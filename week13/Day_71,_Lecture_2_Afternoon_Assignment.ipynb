{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IihPCGvd34PH"
   },
   "source": [
    "# Text Acquisition & Ingestion Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DhLA_w7p34PM"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_stats(corpus):\n",
    "    print(\"Corpus Statistics\")\n",
    "    print(\"Number of documents: \" + str(len(corpus.fileids())))\n",
    "    print(\"Number of paragraphs: \" + str(len(corpus.paras())))\n",
    "    print(\"Number of sentences: \" + str(len(corpus.sents())))\n",
    "    print(\"Number of words: \" + str(len(corpus.words())))\n",
    "    print(\"Vocabulary: \" + str(len(set(w.lower() for w in corpus.words()))))\n",
    "    print(\"Avg chars per word: \" + str(round(len(corpus.raw())/len(corpus.words()),1)))\n",
    "    print(\"Avg words per sentence: \" + str(round(len(corpus.words())/len(corpus.sents()),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZ3ytdXA34PR"
   },
   "source": [
    "### Iterate through the list of article URLs below, scraping the text from each one and saving it to a text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mDbZqPpT34PU"
   },
   "outputs": [],
   "source": [
    "articles = ['http://lite.cnn.io/en/article/h_eac18760a7a7f9a1bf33616f1c4a336d',\n",
    "            'http://lite.cnn.io/en/article/h_de3f82f17d289680dd2b47c6413ebe7c',\n",
    "            'http://lite.cnn.io/en/article/h_72f4dc9d6f35458a89af014b62e625ad',\n",
    "            'http://lite.cnn.io/en/article/h_aa21fe6bf176071cb49e09d422c3adf0',\n",
    "            'http://lite.cnn.io/en/article/h_8ad34a532921c9076cdc9d7390d2f1bc',\n",
    "            'http://lite.cnn.io/en/article/h_84422c79110d9989177cfaf1c5f45fe7',\n",
    "            'http://lite.cnn.io/en/article/h_d010d9580abac3a44c6181ec6fb63d58',\n",
    "            'http://lite.cnn.io/en/article/h_fb11f4e9d7c5323e75b337d9e9e5e368',\n",
    "            'http://lite.cnn.io/en/article/h_7b27f0b131067f8ece6238ac559670ab',\n",
    "            'http://lite.cnn.io/en/article/h_8cae7f735fa9573d470f802063ceffe2',\n",
    "            'http://lite.cnn.io/en/article/h_72c3668280e82576fcc2602b0fa70c14',\n",
    "            'http://lite.cnn.io/en/article/h_d20658fb0e20212051cda0e0a7248c8a',\n",
    "            'http://lite.cnn.io/en/article/h_56611c43d7928120d2ae21666ccc7417',\n",
    "            'http://lite.cnn.io/en/article/h_bda0394e3c5ee7054ee65c022bca7695']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgGlAM2X34Pc"
   },
   "source": [
    "### Ingest the text files generated via web scraping into a corpus and print the corpus statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AfDWUtDr34PX",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, art in enumerate(articles):\n",
    "    afile = open(\"output/articles_text\" + str(i) + \".p\", \"wb\" )\n",
    "    response = requests.get(art)\n",
    "    content = response.text\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    title = soup.find('div', class_='afe4286c').h2.text\n",
    "    afile.write(title.encode(\"UTF-8\"))\n",
    "    \n",
    "    text = soup.find('div', class_='afe4286c').find_all('p')\n",
    "    text_list = [tag.get_text() for tag in text]\n",
    "    \n",
    "    for line in text_list:\n",
    "         afile.write(line.encode(\"UTF-8\"))\n",
    "    \n",
    "    afile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mmybAnNB34Pf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Statistics\n",
      "Number of documents: 14\n",
      "Number of paragraphs: 14\n",
      "Number of sentences: 427\n",
      "Number of words: 13668\n",
      "Vocabulary: 2927\n",
      "Avg chars per word: 5.0\n",
      "Avg words per sentence: 32.0\n"
     ]
    }
   ],
   "source": [
    "PATH = 'output/'\n",
    "DOC_PATTERN = r'articles_text.*\\.p'\n",
    "corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)\n",
    "corpus_stats(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGP_4yfR34Pi"
   },
   "source": [
    "### Parse the O'Reilly Radar RSS feed below, extract the text from each post, and save it to a text file.\n",
    "\n",
    "The content of each post contains HTML tags. Strip those out using the same approach you used for web scraping so that only text is saved to the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CDbqkFCF34Pl"
   },
   "outputs": [],
   "source": [
    "feed = 'http://feeds.feedburner.com/oreilly/radar/atom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "l-a9JgWH34Po",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://feedproxy.google.com/~r/oreilly/radar/atom/~3/7S_cHstbl8Y/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = feedparser.parse(feed)\n",
    "posts = parsed.entries\n",
    "posts[0]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, post in enumerate(posts):   \n",
    "    response = requests.get(posts[0]['link'])\n",
    "    content = response.text\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "    text = soup.find('div', class_='main-post-radar-content').find_all(['p', 'li', 'h3', 'a'])\n",
    "    text_list = [tag.get_text() for tag in text]\n",
    "\n",
    "    afile = open(\"output/articles_rss\" + str(i) + \".p\", \"wb\" )\n",
    "\n",
    "    for line in text_list:\n",
    "        afile.write(line.encode(\"UTF-8\"))\n",
    "    \n",
    "    afile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqK4w9sa34Pr"
   },
   "source": [
    "### Ingest the text files generated via RSS parsing into a corpus and print the corpus statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Statistics\n",
      "Number of documents: 60\n",
      "Number of paragraphs: 120\n",
      "Number of sentences: 2160\n",
      "Number of words: 75960\n",
      "Vocabulary: 583\n",
      "Avg chars per word: 5.5\n",
      "Avg words per sentence: 35.2\n"
     ]
    }
   ],
   "source": [
    "PATH = 'output/'\n",
    "DOC_PATTERN = r'articles_rss.*\\.p'\n",
    "corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)\n",
    "corpus_stats(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BDwjO8t34Pw"
   },
   "source": [
    "### Make an API call to the Hacker News API to retrieve their Ask, Show, and Job category items. \n",
    "\n",
    "- URL: https://hacker-news.firebaseio.com/v0/askstories.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "W7vyWOSN34Px"
   },
   "outputs": [],
   "source": [
    "url = 'https://hacker-news.firebaseio.com/v0/askstories.json'\n",
    "response = requests.get(url)\n",
    "items = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEasqCkr34P0"
   },
   "source": [
    "### Once you have retrieved the item IDs from the URL above, retrieve each item by adding the item ID to the URL below, extract the item's text property, and save the text from each item to disk as its own document.\n",
    "\n",
    "- URL: https://hacker-news.firebaseio.com/v0/item/ITEM_ID_HERE.json\n",
    "\n",
    "The content of some items may contain HTML tags. Strip those out using the same approach you used for web scraping so that only text is saved to the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6Vp7yfWB34P1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Please state the job location and include the keywords\n",
      "REMOTE, INTERNS and&#x2F;or VISA when the corresponding sort of candidate is welcome.\n",
      "When remote work is <i>not</i> an option, include ONSITE.<p>Please only post if you personally are part of the hiring companyâ€”no\n",
      "recruiting firms or job boards. Only one post per company. If it isn&#x27;t a household name,\n",
      "please explain what your company does.<p>Commenters: please don&#x27;t reply to job posts to complain about\n",
      "something. It&#x27;s off topic here.<p>Readers: please only email if you are personally interested in the job.<p>Searchers: Try <a href=\"https:&#x2F;&#x2F;findwork.dev&#x2F;?source=hn\" rel=\"nofollow\">https:&#x2F;&#x2F;findwork.dev&#x2F;?source=hn</a>, <a href=\"https:&#x2F;&#x2F;kennytilton.github.io&#x2F;whoishiring&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;kennytilton.github.io&#x2F;whoishiring&#x2F;</a>,\n",
      "<a href=\"https:&#x2F;&#x2F;hnhired.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;hnhired.com&#x2F;</a>, <a href=\"https:&#x2F;&#x2F;hnjobs.emilburzo.com\" rel=\"nofollow\">https:&#x2F;&#x2F;hnjobs.emilburzo.com</a>, <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10313519\" rel=\"nofollow\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10313519</a>.<p>Don&#x27;t miss these other fine threads:<p><i>Who wants to be hired?</i> <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24969522\" rel=\"nofollow\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24969522</a><p><i>Freelancer? Seeking freelancer?</i> <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24969523\" rel=\"nofollow\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24969523</a>\n",
      "--------------------------------------\n",
      "Dan Kohn[0], executive director at the Linux Foundation, has died[1].<p>[0] <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;user?id=dankohn1\" rel=\"nofollow\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;user?id=dankohn1</a><p>[1] <a href=\"https:&#x2F;&#x2F;twitter.com&#x2F;DrOceanJulie&#x2F;status&#x2F;1322957062444326919\" rel=\"nofollow\">https:&#x2F;&#x2F;twitter.com&#x2F;DrOceanJulie&#x2F;status&#x2F;1322957062444326919</a>\n",
      "--------------------------------------\n",
      "Share your information if you are looking for work. Please use this format:<p><pre><code>  Location:\n",
      "  Remote:\n",
      "  Willing to relocate:\n",
      "  Technologies:\n",
      "  RÃ©sumÃ©&#x2F;CV:\n",
      "  Email:\n",
      "</code></pre>\n",
      "Readers: please only email these addresses to discuss work opportunities.\n",
      "--------------------------------------\n",
      "At my startup Tamber (https:&#x2F;&#x2F;tamber.com) we have had to deliver very high database I&#x2F;O without breaking the bank. Our solution provides two main features:<p>1. Database workers run on AWS Spot Instances for cheap, scalable clusters.<p>2. Pseudo-masterless architecture where clients read&#x2F;write directly to the workers for true horizontal scaling + low latency (implemented in Golang).<p>In order to pull this off, we have also developed:<p><pre><code>  - automatic worker replacement with backfill through Kafka\n",
      "  - spot instance price and stability prediction for optimal instance selection and pre-emptive replacement\n",
      "  - connection pooling w&#x2F; pgbouncer\n",
      "  - zero downtime cluster scaling (adding&#x2F;removing workers, rebalancing table-shards - things Citus only includes in their Enterprise fork).\n",
      "</code></pre>\n",
      "We would love to develop an Open Source service that others can use and contribute to if there is interest. Would love to answer any questions!\n",
      "--------------------------------------\n",
      "Today the Raspberry Pi 400 has been released. Considering that Apple is embracing ARM, I wonder if a similar device would be a successful entry-level product.\n",
      "--------------------------------------\n",
      "Dear HN,<p>I wonder if I&#x27;m the only one wanting this, or if I&#x27;m just bad at searching, but I cannot seem to find any halfway decent phone that is roughly the size of the 1st gen iPhone SE.<p>The old iPhone SE was 124mm tall and had 2GB RAM + 64GB ROM in the most popular model.<p>Putting that into GSMArena tells me that there hasn&#x27;t been any suitable phone released since 2016.<p>https:&#x2F;&#x2F;www.gsmarena.com&#x2F;results.php3?nHeightMax=125&amp;nRamMin=2000&amp;nIntMemMin=64000<p>Why is there such a big hole in the market here?\n",
      "--------------------------------------\n",
      "The browser world is moving forward very fast it is hard to keep tap on what is going on.\n",
      "For instance I missed this:\n",
      "<a href=\"https:&#x2F;&#x2F;developers.google.com&#x2F;web&#x2F;updates&#x2F;2020&#x2F;07&#x2F;referrer-policy-new-chrome-default\" rel=\"nofollow\">https:&#x2F;&#x2F;developers.google.com&#x2F;web&#x2F;updates&#x2F;2020&#x2F;07&#x2F;referrer-p...</a><p>Does some kind of site exists that gathers news about browser updates exist?\n",
      "--------------------------------------\n",
      "I&#x27;m a relatively new freelancer, and I haven&#x27;t found a great way invoice clients. My current strategy depends on the client -- some people I email a work summary each week, some I&#x27;m in constant contact with while working so I just tell them the number of hours, and some I invoice via a self-hosted Invoice Ninja[0] instance.<p>Have you found a way to deal with this that you&#x27;re happy with?\n",
      "--------------------------------------\n",
      "https:&#x2F;&#x2F;www.cloudflarestatus.com&#x2F;<p>https:&#x2F;&#x2F;twitter.com&#x2F;CloudflareHelp&#x2F;status&#x2F;1323308666125242368\n",
      "--------------------------------------\n",
      "Hey HN, I&#x27;m working on a project for school and need to learn a bit more about the revenue model of custom software dev firms.<p>I&#x27;ve been googling, but can&#x27;t seem to get a straight answer. It seems like there&#x27;s an initial project cost &amp; then maintenance revenue ongoing for the software &#x2F; app&#x27;s life. Is that accurate?<p>Appreciate any insight y&#x27;all can provide!\n",
      "--------------------------------------\n",
      "We are launching MVP service (Mobile app dev related) and planning on running a freemium model as a part of our pricing strategy, but there are many ideas on what should we offer in our freemium plan.<p>And I am out of ideas on how can I get feedbacks from our customers on this\n",
      "--------------------------------------\n",
      "Getting feedback from customers is crucial but it seems really difficult to get people to answer a survey or get on a call.<p>I mainly use email to ask for feedback and the response rates are terrible, 2-3%.<p>Are there any effective ways of getting feedback from customers? Tools or templates?\n",
      "--------------------------------------\n",
      "Now that youtube-dl is gone, how are you downloading youtube videos?\n",
      "--------------------------------------\n",
      "Hello HN<p>I am a fullstack engineer with 10+ years of experience in corporate, government, digital media agencies and two startups. A few months ago I started building a small side project to solve a problem that I found interesting. I hit a wall eventually and figured I may be able to speed up my progress if I spoke to someone with more industry knowledge. I spoke to some family who put me in contact with the CEO of a relatively successful company in this field who would be willing to lend an ear to my questions as a personal favour to my family member. Over the course of several weeks we built up a great relationship and further developed this little side-project as well as discussed some of his ideas on ways to further innovate in the industry.<p>To cut a long story short; he offered â‚¬200k in funding to quit my job and co-found a seperate business with him and two of his existing employees. The investment is interest free and can be reduced by â‚¬40k per year. The funding is being offered in a personal capacity and is not coming out of his existing company. There will be a 25% equity split four ways with the goal of further developing some of the ideas we have discussed to date.<p>Myself and one other employee will split the funding as salaries (totalling 1.4 years of runway). I will be the technical arm of the business. The other paid employee will be dedicated fulltime to providing information from within the industry to fill gaps in my knowledge and leverage his extensive network. The CEO and the final member will act as executives in the company (CEO and Chairman) and will work to get the business profitable as quickly as possible.<p>Broadly; what can I do in these extremely early stages that set will set the business on a trajectory for success? I plan on seeking a start-up mentor that I can regularly check in with - is this a good idea? If you have any thoughts, suggestions, books, or whatever to offer, I would be extremely grateful.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "See https:&#x2F;&#x2F;github.com&#x2F;.<p>Nothing on status.github.com yet\n",
      "--------------------------------------\n",
      "I haven&#x27;t been able to find anything about it except for news of the vote back in February.\n",
      "--------------------------------------\n",
      "Cert expired 5 mins ago.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;</a>\n",
      "--------------------------------------\n",
      "(Sorry for bad English. Not my first language.)<p>I had just began work at my first job after finishing university studies. About 1 year back, my first task was to hide negative results about an Israeli start-up that had bad news articles about their business stealing code from competitors.<p>It was never wright with me but it was my first job and I followed instructions of the lead who I was working on this client task with.<p>After a weeks of work, we showed the results to client and the news stories were not appearing in the first pages of Google any more longer.<p>I am stuck on visa and finding jobs is challenging. I have now completed multiple projects of this type of work. I just want to check what does everyone on HN think of this? Is this considered wrong?\n",
      "--------------------------------------\n",
      "It seems this question hasn&#x27;t been asked for some time, so I&#x27;d be interested hear what new (and old) ideas have come up.\n",
      "--------------------------------------\n",
      "I&#x27;m a hands-on kind of person, so I need to install something on my computer and play with alongside reading..<p>My one requirement is that it must be available in ubuntus repositories.<p>Where should I start?\n",
      "--------------------------------------\n",
      "Do they track for example the URLs I share from Safari on iOS? If so what do they use the stats for?\n",
      "--------------------------------------\n",
      "Writing Yet Another Static Site Generator and am wondering how much work to put into the MVP&#x27;s search function. It generates a JSON array of the site keyed by page name, title, and body text. My instinct is simply to do an array filter this time around. If the average site is under, say, 500 pages I assume this will be plenty fast.<p>My Google fu failed with such queries as &quot;how many pages does the average website have&quot;, instead returning pages and pages of articles about SEO and the minimum number of pages a site needs.<p>In a world as analytical as web development I&#x27;m guessing there must be a ton of studies on this subject, but I can&#x27;t find them.\n",
      "--------------------------------------\n",
      "Iâ€™ve been thinking through what has recently been the biggest pain in the ass in the recent react project I did, and id like to know if Iâ€™m crazy or if we did this wrong.<p>We have a few thousand lines of code specifically for managing users and a simple wrapper around our dynamo backend.<p>We couldnâ€™t find a react component for login flows, so we build all this logic ourselves<p>- login page w&#x2F; social login\n",
      "- register page\n",
      "- logout \n",
      "- logic for redirecting you if you were already logged in\n",
      "- logic for redirecting you to login if you arenâ€™t logged in \n",
      "- forgot password\n",
      "- verify\n",
      "- demo user account\n",
      "- notifying users of password requirements\n",
      "- handling failed registration \n",
      "- handling failed logins \n",
      "- handling google social login<p>We integrated with cognito and dynamo, but I think that even with firebase or aws amplify we would have had to write a lot of the logic ourselves.<p>Did we do something wrong? Is this just what you have to do to get logins and a per user backend working?\n",
      "--------------------------------------\n",
      "Around 2007, MIT changed its introductory curriculum from SICP in Scheme to Python.[1-6]<p>How has this worked out?<p>I&#x27;m particularly interested in hearing from MIT students: both those who took the introductory course with Scheme and those who took it with Python, and of the latter especially those who wound up learning Scheme and reading SICP later on, either at MIT or independently.  Do you think you missed out?  Was using Python instead of Scheme the right choice?<p>Insights from TA&#x27;s and teachers also welcome.<p>[1] - https:&#x2F;&#x2F;www.wisdomandwonder.com&#x2F;link&#x2F;2110&#x2F;why-mit-switched-from-scheme-to-python<p>[2] - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11628080<p>[3] - http:&#x2F;&#x2F;lambda-the-ultimate.org&#x2F;node&#x2F;1840<p>[4] - http:&#x2F;&#x2F;lambda-the-ultimate.org&#x2F;node&#x2F;3312<p>[5] - http:&#x2F;&#x2F;people.eecs.berkeley.edu&#x2F;~bh&#x2F;sicp.html<p>[6] - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22994976\n",
      "--------------------------------------\n",
      "I&#x27;m the author of a blingful TUI&#x2F;character graphics library by the name of Notcurses. One of the core competencies of Notcurses is rendering images and video to a terminal (without undue shrinking of the font). Leaving aside asymmetric rendering such as that performed by caca (see Notcurses documentation for an explanation of why I don&#x27;t think this a good general approach), common symmetric rendering techniques include spaces and Unicode half blocks ( and ). This last method is employed by tools like viu and mpv&#x27;s TCT output, and can be considered the general &quot;state of the art&quot;.<p>Notcurses had already gone past this with its Quadblitter, making use of Unicode 3.2&#x27;s quadrant blocks to map 2x2 pixels to a terminal cell. With the advent of Unicode 13&#x27;s Legacy Computing Symbols (and rollout of font support for them), a powerful new symmetric blitting method is made available, mapping 3 rows of 2 columns each to a single cell. This blitter is available as NCBLIT_3x2 in the upcoming Notcurses 2.0.3. I was worried that color loss would be more of a problem, but it ended up looking great!<p>The following images are rendered using all four blitters:<p>https:&#x2F;&#x2F;nick-black.com&#x2F;images&#x2F;worldmap-sexblitter.png (left to right: S, Q, H, ASCII)<p>https:&#x2F;&#x2F;nick-black.com&#x2F;images&#x2F;sexblitter-perfection.png (clockwise from upper left: ASCII, H, Q, S)<p>The algorithm is described here: https:&#x2F;&#x2F;github.com&#x2F;dankamongmen&#x2F;notcurses&#x2F;issues&#x2F;1086<p>code here: https:&#x2F;&#x2F;github.com&#x2F;dankamongmen&#x2F;notcurses&#x2F;blob&#x2F;master&#x2F;src&#x2F;lib&#x2F;blit.c<p>notcurses: https:&#x2F;&#x2F;nick-black.com&#x2F;dankwiki&#x2F;index.php?title=Notcurses<p>hype video: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=cYhZ7myXyyg<p>enjoy! hack on!\n",
      "--------------------------------------\n",
      "There is a great article by A16Z &quot;Platforms vs Verticals and the Next Great Unbundling&quot; where they write on how companies like Airbnb, Tinder or Thumbtack started as an alternative to Craiglist&#x27;s category.<p>Today there are big and active communities in Facebook groups or Subreddits which I believe also could be unbundled and turned into a  businesses like social marketplaces or niche forums. Are there any examples of companies who did that already?\n",
      "--------------------------------------\n",
      "It&#x27;s now pretty clear that learning is more effective when you have a larger dataset of examples. Why are programing documentations only showing one example per function, if any, instead of dozens?\n",
      "--------------------------------------\n",
      "Iâ€™m a first year doctor from Victoria, Australia.\n",
      "This is my first year working in a team-based context, making decisions for patient management.\n",
      "Iâ€™ve had a number of experiences this year with bosses whose management I disagree with. But I havenâ€™t come up with a useful, constructive means to voice this disagreement. \n",
      "Medicine is often a chaotic space to work, which doesnâ€™t help, and your work satisfaction depends fundamentally on your relationships with your team.\n",
      "Looking to hear any tips from others who have wrestled with this issue.\n",
      "--------------------------------------\n",
      "I discovered so many amazing books through the &#x27;users also bought&#x27;. The recommendations that amazon gives now are AI based and terrible in every way. They are never related to what I am looking at currently.\n",
      "--------------------------------------\n",
      "It&#x27;s a commonly-voiced concern that jobs are bullshit. The community could take specific needs and connect them to specific bullshit jobs, telling fellow professionals what they should be doing instead. Why do we not do this?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "So I&#x27;ve been thinking about this for a while and diversifying services as much as possible (mail, drive, docs etc) but Photos is one service that I can&#x27;t replace.<p>Of course I take backups of the (super messy) Takeout, and use the API to make (incomplete, lower quality) backups of photos.<p>None are ideal though. So, here&#x27;s my question, what&#x27;s your contingency plan if you lose access to your Google account?\n",
      "--------------------------------------\n",
      "Our 2 year old startup had a 409a valuation to, amongst other things, set the strike price of our options. The board held back significant amounts of information, including the total value and fair market value. The strike price was set at 1.25 per share, after they had suggested numerous people would get a price of 1 per share. Come to find out, the fair market value is .90 per share, which puts the value of the company at less than what they originally told us and to me shows some shady behavior.<p>Is it typical for a strike price to be set so much above fair market value? Is it usual to not divulge that information to share holders and optionees?\n",
      "--------------------------------------\n",
      "would it be better if Andriod, iOS and all Browsers introduce containerization for every web and native apps. This should very well help tackle the cross-tracking of user behavior and they will live in their own contained world, thus reducing their ability to track anything outside of their own running service.\n",
      "--------------------------------------\n",
      "I started to download some private thoughts and notes in a public bare GitHub repo.<p>I find it a good storage medium for some of my notes, bookmarks, lists.\n",
      "And has benefits such as being able to simply link to my thoughts rather than composing the n-th email about the same subject.<p>Over time I also want to throw in code i have laying around, host my CV and maybe make it my homepage.<p>Is this a thing people do? Does this thing have a name?<p>GHB would be the natural acronym and that would be a terrible idea.<p>P.S. Thank you HN for being a place where I can ask this question and knowing people get it. I appreciate the feeling of community.\n",
      "P.P.S. If you&#x27;re reading this and thinking: PURDAH. Call me\n",
      "--------------------------------------\n",
      "We seem stuck in a very old way of writing software. If you were to reinvent it, what would it look like?\n",
      "--------------------------------------\n",
      "When doing research or just navigating I find myself opening multiple tabs that I wan&#x27;t to deep dive in later but never have the time to. This leads to leaving multiple tabs open in my browser which I eventually group in different windows but still leave untouched. After some days&#x2F;weeks I sometimes save each &quot;Research Session&quot; window in a Session using FFs Tab Session Manager extension. However, the flow of that research session is lost.<p>Is there any extension or tool with which one can visualize the web history as a graph, seeing which site lead to which and maybe clustering nodes by topic?<p>How do you personally keep track of such sessions? I am too lazy to transfer the knowledge from those sites to some knowledge base or to use bookmarks with categories (I like the idea of being aware of the referral that brought me to a particular site).\n",
      "--------------------------------------\n",
      "I have several old email addresses. I have used them for sign ups etc and it seems impossible to just close them. I want to transition to a more private, paid email address.<p>Have you managed to transition off and gracefully deprecate old email addresses? How?\n",
      "--------------------------------------\n",
      "What do you think about pop-up try out mini stores for the products you want to buy via e-commerce or other online stores?\n",
      "--------------------------------------\n",
      "I&#x27;ve been in tech for like 20 years. I&#x27;ve started a couple of companies, I&#x27;ve worked for way more. And... I&#x27;m done. I mean completely burned out, hating on the industry, and really just wondering what I can do with my life.<p>I&#x27;m not with the mock-woke companies that lie to themselves. I&#x27;m done with the frat-boy companies. I&#x27;m done with people changing the world by making XYZ obsolete, or disrupting ABC. I&#x27;m done with companies pretending to do good or well, while in reality just being rent-seeking behemoths. I&#x27;m sick of watching our brightest pollute the world with ad tech. I&#x27;m just done.<p>Does anyone else feel this? Did you get out? What do you do now, and how do you reconcile the sheer difference in dollars?\n",
      "--------------------------------------\n",
      "As the title suggests, my outlook.com account has been suspended due to violations. However, I can&#x27;t find any reference in their terms and conditions to my specific violation.<p>The reason is that I use NordVPN to connect to the internet.<p>Any ideas? I can&#x27;t do anything without that account as changing my email on many services requires access to my old email.<p>Over the years I have read many stories on here of this happening to people, mainly on Google services, and it pretty much stops them dead in their tracks... well, now it&#x27;s happened to me.<p>I&#x27;ve been thinking about it over the last several days and, legitimately, the only possible recourse is to run your own email server. Now this has it&#x27;s own issues but it means I have (almost) total control over my data.<p>Anyway, as the title suggests, any ideas? I just need to get it reinstated so I can move all my email away from it now.\n",
      "--------------------------------------\n",
      "My feeling are - itâ€™s a distraction because of outrageous number of requirements and effort&#x2F;cost required. To me, the process is geared towards more established players and as SMB itâ€™s not worth it.<p>Iâ€™m curious to hear from the community on your experiences with RFP - do you respond to unsolicited requests? How did it work out for you? Have you won a big contract&#x2F;license out of RFP?\n",
      "--------------------------------------\n",
      "I want to build an iOS app to make my life easier. I&#x27;m certain that other people in my line of work have the same problem, and could benefit from a convenient solution. The MVP requirements that I&#x27;ve listed out are complex enough (VOIP capability, some api calls, database stuff) that I&#x27;m wondering if I&#x27;ll be able to do it with an &quot;app building&quot; service or if I&#x27;ll need to learn how to code it, or pay someone to code it.<p>Not sure this is enough information for a meaningful answer, so happy to chime in as necessary in the comments.\n",
      "--------------------------------------\n",
      "The last few weeks have been very disheartening as the disease is spreading more and more rapidly, to the point where any hopes of &quot;getting back to normal&quot; are feeling quite far out of reach.<p>How the hell do we actually&#x2F;pragmatically solve this thing? Is a widely accessible vaccine the only option? How long will that take?\n",
      "--------------------------------------\n",
      "Let me put this as simple as I can: \n",
      "Writing tutorials on Medium means you are putting them behind a paywall, thus restricting learning opportunities.<p>Medium is not StackOverflow, it limits the number of articles that can be freely read.<p>If you ever learned something from a blog or from stackoverflow do contribute back by sharing your knowledge open on the internet not behind a paywall.\n",
      "--------------------------------------\n",
      "I recently discovered how to break a tough cycle that held me back professionally so wanted to share (in hopes of helping even 1 person like me) and to see how you all manage.<p>I had a bad habit of working until I would burn out, in hopes that I would serendipitously learn a few tricks&#x2F;hacks and grow. This went on for years. Yet every time I had a moment to reflect, I would realize that I wasn&#x27;t fulfilled, I learned a few meaningless skills, but wasn&#x27;t anywhere near my personal &#x2F; professional goals. So I started doing the following things and it has changed my life:\n",
      "1) write down how my day went every day\n",
      "2) document why it went well, want went &#x27;not so well&#x27;, and what i learned\n",
      "3) systematically gather feedback from peers and mentors i trusted<p>I now have a couple of months worth of data and can systematically tell when i&#x27;ll have a great&#x2F;good&#x2F;bad day and where i need to focus to grow (e.g., my communications skills). I feel much sharper and more growth and goal oriented - it sounds cliche but i feel like i have found a new lease on my professional life.<p>Curious to hear HN friends how you guys manage it all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Genuinely curious and admit I donâ€™t understand this technology fully but if the main use case is verifying something Why canâ€™t people vote using their phones and results be instantaneous.<p>Asking as the us election is approaching and we know itâ€™s going to be a shitshow and this is if we are lucky. Else it will be something .. well letâ€™s not go there.\n"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    url = 'https://hacker-news.firebaseio.com/v0/item/' + str(item) + '.json'\n",
    "    response = requests.get(url)\n",
    "    content = response.text\n",
    "    \n",
    "    obj = eval(content)\n",
    "    if ('text' in obj.keys()):\n",
    "        text = obj['text']\n",
    "        print('--------------------------------------')\n",
    "        print(text)\n",
    "\n",
    "#     afile = open(\"output/articles_rss\" + str(i) + \".p\", \"wb\" )\n",
    "\n",
    "#     for line in text_list:\n",
    "#         afile.write(line.encode(\"UTF-8\"))\n",
    "    \n",
    "#     afile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw9-v8sK34P5"
   },
   "source": [
    "### Ingest the text files generated via API into a corpus and print the corpus statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcsiPdkx34P7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Day 71, Lecture 2: Afternoon Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
