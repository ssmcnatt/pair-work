{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iCUbt7u4JIO"
   },
   "source": [
    "# Text Data Cleaning and Preprocessing Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wuqMJsi-4JIS"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_stats(corpus):\n",
    "    print(\"Corpus Statistics\")\n",
    "    print(\"Number of documents: \" + str(len(corpus.fileids())))\n",
    "    print(\"Number of paragraphs: \" + str(len(corpus.paras())))\n",
    "    print(\"Number of sentences: \" + str(len(corpus.sents())))\n",
    "    print(\"Number of words: \" + str(len(corpus.words())))\n",
    "    print(\"Vocabulary: \" + str(len(set(w.lower() for w in corpus.words()))))\n",
    "    print(\"Avg chars per word: \" + str(round(len(corpus.raw())/len(corpus.words()),1)))\n",
    "    print(\"Avg words per sentence: \" + str(round(len(corpus.words())/len(corpus.sents()),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCY5p4L54JIY"
   },
   "source": [
    "### Read the O'Reilly RSS plain text file articles into a corpus using the NLTK's PlaintextCorpusReader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lmNkoVRZ4JIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Statistics\n",
      "Number of documents: 60\n",
      "Number of paragraphs: 61\n",
      "Number of sentences: 1801\n",
      "Number of words: 58848\n",
      "Vocabulary: 6866\n",
      "Avg chars per word: 5.2\n",
      "Avg words per sentence: 32.7\n"
     ]
    }
   ],
   "source": [
    "PATH = 'oreilly_radar/'\n",
    "DOC_PATTERN = r'articles_rss.*\\.p'\n",
    "corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)\n",
    "corpus_stats(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJI6AbGA4JIg"
   },
   "source": [
    "### Iterate through the fileids in the corpus, extract the raw text of each document, and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UL7Cjcby4JIi",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for fileid in corpus.fileids():\n",
    "    doc = corpus.raw(fileid)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7JuwNTW4JIn"
   },
   "source": [
    "### Sentence tokenize each document in the list of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8zbqurmN4JIp",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Perhaps the most important event this month isn’t technical, but the start of the US Justice Dept.’s lawsuit against Google.',\n",
       " 'That will certainly play out over years rather than months, but it’s significance is less about this particular case than the idea that legal and regulatory systems will play a large role in the evolution of technology in the US.',\n",
       " 'In the short term, it’s worth watching the CPPA, GDPR, California’s Props 22 and 24, and FCC interference with social media’s enforcement of rules around community behavior.',\n",
       " 'Long term, this is only the beginning.Artificial Intelligence and Machine LearningPartial differential equations are the key to a number of difficult and important problems.',\n",
       " 'In a surprising breakthrough, it’s been shown that deep learning can be used to solve PDEs, and that they are orders of magnitude faster than typical numerical methods.solve PDEsAgence is a dynamic film/multiplayer VR game with intelligent agents.',\n",
       " 'AI might not be what pushes VR to commercial success, but it will certainly be a part.AgenceTowards more trustworthy models: Research on models that can take into account physical laws, error, and missing information makes AI more trustworthy.Towards more trustworthy modelsAI more trustworthy“Less than one shot learning”: when the number of classes is larger than the number of sample.',\n",
       " 'The key idea here is “soft labelling,” which allows labels to represent characteristics shared between multiple items in the sample.Less than one shot learningVery small neural networks adapted from worms’ nervous systems are able to perform tasks as well as networks thousands of times larger.Very small neural networksA device that can mimic the behavior of a neuron might eventually make it possible to emulate a brain, without requiring a lot of power.mimic the behavior of a neuronAI is not magic, even when it is effective.',\n",
       " 'Integrating AI into medical practice requires work–serious human work in rethinking social structures, communications, and hierarchies.',\n",
       " 'This work frequently falls to the nursing staff, whose contribution is often undervalued.Integrating AI into medical practiceAwful-AI is a GitHub repo for tracking “awful uses of AI.”\\xa0 Autonomous weapons, racist AI, social credit, and scams: they’re all here.',\n",
       " 'It would be funny if it wasn’t sad (and real).Awful-AIPattern-exploited training (PET) is a new NLP technique that, on some benchmarks, exceeds GPT-3 performance while only using 223 million parameters (as opposed to 175 billion).',\n",
       " 'While 223 million is still a large number, that’s a factor of almost 1000 less than GPT-3.PETexceeds GPT-3 performanceDoes explainable AI actually increase trust?',\n",
       " 'Perhaps not.',\n",
       " 'Explanations can be distortions (lies).',\n",
       " 'Auditing is a more trustworthy approach.Perhaps notInfrastructure and OperationsMicrosoft’s Open Source Dapr Distributed Runtime is an abstraction layer on top of Kubernetes (and much more) to simplify building software that runs in a distributed multi-cloud environment.Dapr Distributed RuntimeCloud waste: How much cloud spending is actually used?',\n",
       " 'Perhaps as much as 45% is wasted on overprovisioning, unexpected costs, and resources that go unused.Cloud wasteBuilding continuously resilient systems starts with chaos engineering: Adrian Cockroft on failover theater, the cloud, and reliability.continuously resilientProgrammingAn all no-code startup: Yes, it’s possible.',\n",
       " 'It’s time to start thinking about the no-code “stack.”An all no-code startupThe kernel within the Linux kernel: eBPF can run sandboxed programs within the kernel’s memory space; it’s a convenient way to write kernel extensions and, conceivably, to replace much of the existing kernel with an eBPF-based microkernel.eBPFIt’s worth reading @sogrady’s thoughts on how developer experience needs to change in order to build more tightly integrated software across multiple platforms.developer experienceSecurity and PrivacyBotched identity and access management (IAM) configuration is a huge problem for cloud security.',\n",
       " 'Understanding security configuration is nearly impossible for humans.identity and access management (IAM)Redesigning corporate networks for working at home: Corporate networks need to be re-thought; working from home raises new security issues and increases bandwidth requirements.Redesigning corporate networks for working at homeMicrosoft disables Trickbot, a ransomware network that was targeting the US election.',\n",
       " 'What’s particularly interesting is that Microsoft used trademark law to get a court order allowing them to take control over the Trickbot servers.Microsoft disables TrickbotHave IoT vendors learned anything about security yet?',\n",
       " 'Apparently not.',\n",
       " 'Your coffee maker on ransomware.Your coffee maker on ransomwareEconomiesIndoor farming, food security, climate and COVID in Singapore: how do you guarantee a food supply in the face of supply chain breakdowns and an increasingly erratic climate, in a densely populated country with almost no arable land?Indoor farming, food security, climate and COVID in SingaporeTowards a digital Euro: The European Central Bank is taking the first steps towards a digital version of the Euro.',\n",
       " 'It’s behind China (but ahead of the US) in its steps towards digital currency.Towards a digital EuroHardwareQuantum fast fourier transform (QFFT): Want to reinvent digital signal processing on quantum computers?',\n",
       " 'This is another game changer, and one of the few classical algorithms that have been reinvented for quantum computers.QFFTMulti-state memory: not just zeros and ones.',\n",
       " 'Moore’s law applies to memory, too, and the best way to get around the fundamental limitation (ever-smaller features) might be to design memory that goes beyond binary.',\n",
       " 'Multi-state memory might also be a big step forward in neuromorphic computing.Multi-state memory:beyond binaryPrinting sensors directly on the body without heat: Who needs an iPhone?',\n",
       " 'These sensors could be revolutionary for tasks like COVID monitoring and personalized medicine.Printing sensors directly on the body without heatRobotic fabric: Developers have made fabric that can change its shape programmably.',\n",
       " 'Robotic clothes?',\n",
       " 'Robotic fabricWebDo Not Track failed.',\n",
       " 'Global Privacy Control (GPC) is essentially Do Not Track with legal teeth.',\n",
       " 'Will it succeed?',\n",
       " 'Currently implemented by the Brave browser and some plugins for other browsers.Global Privacy ControlFirefox’s campaign to “Unfck the Internet” gives us a reason to return to Firefox.',\n",
       " 'The campaign is built around a set of plugins for controlling political ads, social media surveillance, warning others about inappropriate YouTube recommendations, and more.',\n",
       " 'Putting social media control in the browser?',\n",
       " 'It might work.',\n",
       " 'Unfck the Internet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents = [sent_tokenize(doc) for doc in docs]\n",
    "doc_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqT7V6zZ4JIu"
   },
   "source": [
    "### Word tokenize each sentence within each document.\n",
    "\n",
    "You should end up with a nested list structure where the outer list contains all the sentences in each document and the inner list contains the tokenized sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "17JMEoHe4JIv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_tokenized = []\n",
    "for sents in doc_sents:\n",
    "    temp = []\n",
    "    for sent in sents:\n",
    "        temp.append(word_tokenize(sent))\n",
    "    s_tokenized.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pk1r_y4C4JIz"
   },
   "source": [
    "### Tag each token with its part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Flze4fS-4JI0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_pos = []\n",
    "for sents in s_tokenized:\n",
    "    temp = []\n",
    "    for sent in sents:\n",
    "        temp.append(pos_tag(sent))\n",
    "    s_pos.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmIltOA44JI5"
   },
   "source": [
    "### Word tokenize the raw text of each document and remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZVUcQFkJ4JI7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenized = [word_tokenize(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stopwords = []\n",
    "for token in tokenized:\n",
    "    temp = []\n",
    "    for word in token:\n",
    "        if word.lower() not in stopwords.words('english'):\n",
    "            temp.append(word.lower())\n",
    "    no_stopwords.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAZggM574JI_"
   },
   "source": [
    "### For every document, stem all the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JgLS7PPD4JJB"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "stem_words = []\n",
    "for token in tokenized:\n",
    "    temp = []\n",
    "    for word in token:\n",
    "        temp.append(stemmer.stem(word.lower()))\n",
    "    stem_words.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2N4mHrZ4JJQ"
   },
   "source": [
    "### Iterate through each document, computing and printing the following document statistics for each.\n",
    "\n",
    "- Number of sentences\n",
    "- Average words per sentence\n",
    "- Vocabulary\n",
    "- Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7kBjbVZb4JJR",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Number of sentences =  34\n",
      "Average words per sentence =  33.6764705882353\n",
      "Unique words (vocabulary) =  545\n",
      "Lexical diversity =  0.4759825327510917\n",
      "-----------------------------\n",
      "Number of sentences =  10\n",
      "Average words per sentence =  28.8\n",
      "Unique words (vocabulary) =  156\n",
      "Lexical diversity =  0.5416666666666666\n",
      "-----------------------------\n",
      "Number of sentences =  8\n",
      "Average words per sentence =  34.5\n",
      "Unique words (vocabulary) =  167\n",
      "Lexical diversity =  0.605072463768116\n",
      "-----------------------------\n",
      "Number of sentences =  4\n",
      "Average words per sentence =  53.75\n",
      "Unique words (vocabulary) =  130\n",
      "Lexical diversity =  0.6046511627906976\n",
      "-----------------------------\n",
      "Number of sentences =  43\n",
      "Average words per sentence =  32.395348837209305\n",
      "Unique words (vocabulary) =  599\n",
      "Lexical diversity =  0.43000717875089733\n",
      "-----------------------------\n",
      "Number of sentences =  8\n",
      "Average words per sentence =  25.75\n",
      "Unique words (vocabulary) =  143\n",
      "Lexical diversity =  0.6941747572815534\n",
      "-----------------------------\n",
      "Number of sentences =  5\n",
      "Average words per sentence =  32.6\n",
      "Unique words (vocabulary) =  108\n",
      "Lexical diversity =  0.6625766871165644\n",
      "-----------------------------\n",
      "Number of sentences =  7\n",
      "Average words per sentence =  44.0\n",
      "Unique words (vocabulary) =  171\n",
      "Lexical diversity =  0.5551948051948052\n",
      "-----------------------------\n",
      "Number of sentences =  10\n",
      "Average words per sentence =  33.4\n",
      "Unique words (vocabulary) =  182\n",
      "Lexical diversity =  0.5449101796407185\n",
      "-----------------------------\n",
      "Number of sentences =  47\n",
      "Average words per sentence =  41.46808510638298\n",
      "Unique words (vocabulary) =  657\n",
      "Lexical diversity =  0.3370959466393022\n",
      "-----------------------------\n",
      "Number of sentences =  7\n",
      "Average words per sentence =  27.714285714285715\n",
      "Unique words (vocabulary) =  116\n",
      "Lexical diversity =  0.5979381443298969\n",
      "-----------------------------\n",
      "Number of sentences =  5\n",
      "Average words per sentence =  50.4\n",
      "Unique words (vocabulary) =  143\n",
      "Lexical diversity =  0.5674603174603174\n",
      "-----------------------------\n",
      "Number of sentences =  13\n",
      "Average words per sentence =  19.076923076923077\n",
      "Unique words (vocabulary) =  165\n",
      "Lexical diversity =  0.6653225806451613\n",
      "-----------------------------\n",
      "Number of sentences =  36\n",
      "Average words per sentence =  27.5\n",
      "Unique words (vocabulary) =  387\n",
      "Lexical diversity =  0.39090909090909093\n",
      "-----------------------------\n",
      "Number of sentences =  4\n",
      "Average words per sentence =  33.0\n",
      "Unique words (vocabulary) =  95\n",
      "Lexical diversity =  0.7196969696969697\n",
      "-----------------------------\n",
      "Number of sentences =  11\n",
      "Average words per sentence =  20.636363636363637\n",
      "Unique words (vocabulary) =  135\n",
      "Lexical diversity =  0.5947136563876652\n",
      "-----------------------------\n",
      "Number of sentences =  41\n",
      "Average words per sentence =  31.097560975609756\n",
      "Unique words (vocabulary) =  574\n",
      "Lexical diversity =  0.45019607843137255\n",
      "-----------------------------\n",
      "Number of sentences =  7\n",
      "Average words per sentence =  27.285714285714285\n",
      "Unique words (vocabulary) =  131\n",
      "Lexical diversity =  0.6858638743455497\n",
      "-----------------------------\n",
      "Number of sentences =  169\n",
      "Average words per sentence =  29.810650887573964\n",
      "Unique words (vocabulary) =  1441\n",
      "Lexical diversity =  0.28602620087336245\n",
      "-----------------------------\n",
      "Number of sentences =  13\n",
      "Average words per sentence =  24.307692307692307\n",
      "Unique words (vocabulary) =  174\n",
      "Lexical diversity =  0.5506329113924051\n",
      "-----------------------------\n",
      "Number of sentences =  4\n",
      "Average words per sentence =  43.75\n",
      "Unique words (vocabulary) =  106\n",
      "Lexical diversity =  0.6057142857142858\n",
      "-----------------------------\n",
      "Number of sentences =  4\n",
      "Average words per sentence =  44.25\n",
      "Unique words (vocabulary) =  113\n",
      "Lexical diversity =  0.6384180790960452\n",
      "-----------------------------\n",
      "Number of sentences =  47\n",
      "Average words per sentence =  33.8936170212766\n",
      "Unique words (vocabulary) =  584\n",
      "Lexical diversity =  0.36660389202762084\n",
      "-----------------------------\n",
      "Number of sentences =  162\n",
      "Average words per sentence =  32.18518518518518\n",
      "Unique words (vocabulary) =  1293\n",
      "Lexical diversity =  0.24798619102416572\n",
      "-----------------------------\n",
      "Number of sentences =  13\n",
      "Average words per sentence =  27.0\n",
      "Unique words (vocabulary) =  192\n",
      "Lexical diversity =  0.5470085470085471\n",
      "-----------------------------\n",
      "Number of sentences =  92\n",
      "Average words per sentence =  26.41304347826087\n",
      "Unique words (vocabulary) =  684\n",
      "Lexical diversity =  0.2814814814814815\n",
      "-----------------------------\n",
      "Number of sentences =  9\n",
      "Average words per sentence =  24.444444444444443\n",
      "Unique words (vocabulary) =  145\n",
      "Lexical diversity =  0.6590909090909091\n",
      "-----------------------------\n",
      "Number of sentences =  11\n",
      "Average words per sentence =  25.90909090909091\n",
      "Unique words (vocabulary) =  165\n",
      "Lexical diversity =  0.5789473684210527\n",
      "-----------------------------\n",
      "Number of sentences =  7\n",
      "Average words per sentence =  39.142857142857146\n",
      "Unique words (vocabulary) =  151\n",
      "Lexical diversity =  0.551094890510949\n",
      "-----------------------------\n",
      "Number of sentences =  39\n",
      "Average words per sentence =  30.17948717948718\n",
      "Unique words (vocabulary) =  525\n",
      "Lexical diversity =  0.4460492778249788\n",
      "-----------------------------\n",
      "Number of sentences =  4\n",
      "Average words per sentence =  70.25\n",
      "Unique words (vocabulary) =  173\n",
      "Lexical diversity =  0.6156583629893239\n",
      "-----------------------------\n",
      "Number of sentences =  9\n",
      "Average words per sentence =  34.888888888888886\n",
      "Unique words (vocabulary) =  160\n",
      "Lexical diversity =  0.5095541401273885\n",
      "-----------------------------\n",
      "Number of sentences =  4\n",
      "Average words per sentence =  46.0\n",
      "Unique words (vocabulary) =  110\n",
      "Lexical diversity =  0.5978260869565217\n",
      "-----------------------------\n",
      "Number of sentences =  193\n",
      "Average words per sentence =  32.12435233160622\n",
      "Unique words (vocabulary) =  1493\n",
      "Lexical diversity =  0.24080645161290323\n",
      "-----------------------------\n",
      "Number of sentences =  10\n",
      "Average words per sentence =  24.2\n",
      "Unique words (vocabulary) =  164\n",
      "Lexical diversity =  0.6776859504132231\n",
      "-----------------------------\n",
      "Number of sentences =  75\n",
      "Average words per sentence =  26.133333333333333\n",
      "Unique words (vocabulary) =  602\n",
      "Lexical diversity =  0.30714285714285716\n",
      "-----------------------------\n",
      "Number of sentences =  7\n",
      "Average words per sentence =  38.285714285714285\n",
      "Unique words (vocabulary) =  170\n",
      "Lexical diversity =  0.6343283582089553\n",
      "-----------------------------\n",
      "Number of sentences =  11\n",
      "Average words per sentence =  36.81818181818182\n",
      "Unique words (vocabulary) =  230\n",
      "Lexical diversity =  0.5679012345679012\n",
      "-----------------------------\n",
      "Number of sentences =  12\n",
      "Average words per sentence =  38.083333333333336\n",
      "Unique words (vocabulary) =  255\n",
      "Lexical diversity =  0.5579868708971554\n",
      "-----------------------------\n",
      "Number of sentences =  6\n",
      "Average words per sentence =  33.333333333333336\n",
      "Unique words (vocabulary) =  131\n",
      "Lexical diversity =  0.655\n",
      "-----------------------------\n",
      "Number of sentences =  43\n",
      "Average words per sentence =  29.41860465116279\n",
      "Unique words (vocabulary) =  484\n",
      "Lexical diversity =  0.3826086956521739\n",
      "-----------------------------\n",
      "Number of sentences =  8\n",
      "Average words per sentence =  32.875\n",
      "Unique words (vocabulary) =  166\n",
      "Lexical diversity =  0.6311787072243346\n",
      "-----------------------------\n",
      "Number of sentences =  19\n",
      "Average words per sentence =  28.263157894736842\n",
      "Unique words (vocabulary) =  271\n",
      "Lexical diversity =  0.5046554934823091\n",
      "-----------------------------\n",
      "Number of sentences =  11\n",
      "Average words per sentence =  26.818181818181817\n",
      "Unique words (vocabulary) =  169\n",
      "Lexical diversity =  0.5728813559322034\n",
      "-----------------------------\n",
      "Number of sentences =  12\n",
      "Average words per sentence =  30.583333333333332\n",
      "Unique words (vocabulary) =  198\n",
      "Lexical diversity =  0.5395095367847411\n",
      "-----------------------------\n",
      "Number of sentences =  10\n",
      "Average words per sentence =  29.2\n",
      "Unique words (vocabulary) =  169\n",
      "Lexical diversity =  0.5787671232876712\n",
      "-----------------------------\n",
      "Number of sentences =  165\n",
      "Average words per sentence =  32.50909090909091\n",
      "Unique words (vocabulary) =  1172\n",
      "Lexical diversity =  0.2184936614466816\n",
      "-----------------------------\n",
      "Number of sentences =  6\n",
      "Average words per sentence =  43.666666666666664\n",
      "Unique words (vocabulary) =  168\n",
      "Lexical diversity =  0.6412213740458015\n",
      "-----------------------------\n",
      "Number of sentences =  60\n",
      "Average words per sentence =  22.316666666666666\n",
      "Unique words (vocabulary) =  512\n",
      "Lexical diversity =  0.38237490664675133\n",
      "-----------------------------\n",
      "Number of sentences =  10\n",
      "Average words per sentence =  29.6\n",
      "Unique words (vocabulary) =  184\n",
      "Lexical diversity =  0.6216216216216216\n",
      "-----------------------------\n",
      "Number of sentences =  10\n",
      "Average words per sentence =  26.8\n",
      "Unique words (vocabulary) =  171\n",
      "Lexical diversity =  0.6380597014925373\n",
      "-----------------------------\n",
      "Number of sentences =  8\n",
      "Average words per sentence =  41.5\n",
      "Unique words (vocabulary) =  190\n",
      "Lexical diversity =  0.572289156626506\n",
      "-----------------------------\n",
      "Number of sentences =  56\n",
      "Average words per sentence =  26.107142857142858\n",
      "Unique words (vocabulary) =  481\n",
      "Lexical diversity =  0.3290013679890561\n",
      "-----------------------------\n",
      "Number of sentences =  8\n",
      "Average words per sentence =  39.625\n",
      "Unique words (vocabulary) =  179\n",
      "Lexical diversity =  0.5646687697160884\n",
      "-----------------------------\n",
      "Number of sentences =  12\n",
      "Average words per sentence =  25.166666666666668\n",
      "Unique words (vocabulary) =  189\n",
      "Lexical diversity =  0.6258278145695364\n",
      "-----------------------------\n",
      "Number of sentences =  5\n",
      "Average words per sentence =  29.4\n",
      "Unique words (vocabulary) =  98\n",
      "Lexical diversity =  0.6666666666666666\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences =  10\n",
      "Average words per sentence =  38.8\n",
      "Unique words (vocabulary) =  208\n",
      "Lexical diversity =  0.5360824742268041\n",
      "-----------------------------\n",
      "Number of sentences =  84\n",
      "Average words per sentence =  40.98809523809524\n",
      "Unique words (vocabulary) =  1011\n",
      "Lexical diversity =  0.29363926808016266\n",
      "-----------------------------\n",
      "Number of sentences =  12\n",
      "Average words per sentence =  27.25\n",
      "Unique words (vocabulary) =  171\n",
      "Lexical diversity =  0.5229357798165137\n",
      "-----------------------------\n",
      "Number of sentences =  51\n",
      "Average words per sentence =  25.705882352941178\n",
      "Unique words (vocabulary) =  454\n",
      "Lexical diversity =  0.34630053394355453\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(doc_sents)):\n",
    "    num_sent = len(doc_sents[i])\n",
    "    avg_words_sent = sum([len(sent) for sent in s_tokenized[i]]) / num_sent\n",
    "    vocab = len(set([word.lower() for word in word_tokenize(docs[i])]))\n",
    "    lex_div = vocab / len(word_tokenize(docs[i]))\n",
    "\n",
    "    print('-----------------------------')\n",
    "    print('Number of sentences = ', num_sent)\n",
    "    print('Average words per sentence = ', avg_words_sent)\n",
    "    print('Unique words (vocabulary) = ', vocab)\n",
    "    print('Lexical diversity = ', lex_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Day 72, Lecture 1: Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
