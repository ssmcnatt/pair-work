{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ilinechart(df, x, y, groups=None, title=''):\n",
    "    fig = px.line(df, x=x, y=y, color=groups, title=title, \n",
    "                  template='none').update(layout=dict(title=dict(x=0.5)))\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linechart(df, x, length=8, width=15, title=\"\"):\n",
    "    if df.index.name != x:\n",
    "        df = df.set_index(x)\n",
    "\n",
    "    ax = df.plot(figsize=(width,length), cmap=\"Set2\")\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1),\n",
    "              fancybox=True, shadow=True, ncol=4)\n",
    "    \n",
    "    plt.title(title + \"\\n\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iscatter(df, x, y, color=None, size=None, title=''):\n",
    "    fig = px.scatter(df, x=x, y=y, color=color, size=size, \n",
    "                     title=title, template='none')\n",
    "    \n",
    "    fig.update_traces(marker_line_color='black', \n",
    "                  marker_line_width=1)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans(df, clusters=2):\n",
    "    model = KMeans(n_clusters=clusters, random_state=42)\n",
    "    clusters = model.fit_predict(df)\n",
    "    results = df.copy()\n",
    "    results['Cluster'] = clusters\n",
    "    \n",
    "    cluster_size = results.groupby(['Cluster']).size().reset_index()\n",
    "    cluster_size.columns = ['Cluster', 'Count']\n",
    "    cluster_means = results.groupby(['Cluster'], as_index=False).mean()\n",
    "    summary = pd.merge(cluster_size, cluster_means, on='Cluster')\n",
    "    \n",
    "    return results, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_stats(corpus):\n",
    "    print(\"Corpus Statistics\")\n",
    "    print(\"Number of documents: \" + str(len(corpus.fileids())))\n",
    "    print(\"Number of paragraphs: \" + str(len(corpus.paras())))\n",
    "    print(\"Number of sentences: \" + str(len(corpus.sents())))\n",
    "    print(\"Number of words: \" + str(len(corpus.words())))\n",
    "    print(\"Vocabulary: \" + str(len(set(w.lower() for w in corpus.words()))))\n",
    "    print(\"Avg chars per word: \" + str(round(len(corpus.raw())/len(corpus.words()),1)))\n",
    "    print(\"Avg words per sentence: \" + str(round(len(corpus.words())/len(corpus.sents()),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_stats(doc):\n",
    "    sents = sent_tokenize(doc)\n",
    "    tokens = word_tokenize(doc)\n",
    "    words = [token.lower() for token in tokens \n",
    "             if not token.lower() in stopwords.words('english')\n",
    "             if not token in string.punctuation]\n",
    "\n",
    "    num_sents = len(sents)\n",
    "    num_tokens = len(tokens)\n",
    "    num_words = len(words)\n",
    "    vocab = len(set(words))\n",
    "    characters = sum([len(word) for word in words])\n",
    "    \n",
    "    spacy_doc = nlp(doc)\n",
    "    remove = ['DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY', \n",
    "              'ORDINAL', 'CARDINAL']\n",
    "    entities = [entity.text for entity in spacy_doc.ents \n",
    "                if not entity.label_ in remove]\n",
    "\n",
    "    num_entities = len(set(entities))\n",
    "    words_sent = num_words / num_sents\n",
    "    char_word = characters / num_words\n",
    "    lex_div = vocab / num_words\n",
    "    \n",
    "    stats = [num_sents, num_tokens, num_words, vocab, num_entities, \n",
    "             words_sent, char_word, lex_div]\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(text, colormap='tab10', background_color='white'):\n",
    "    cloud = WordCloud(width=1600, height=800, stopwords=STOPWORDS,\n",
    "                      colormap=colormap, \n",
    "                      background_color=background_color).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(docs): \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    stemmer = SnowballStemmer('english') \n",
    "    \n",
    "    preprocessed = []\n",
    "    for doc in docs: \n",
    "        tokenized = word_tokenize(doc)\n",
    "        cleaned = [stemmer.stem(lemmatizer.lemmatize(token.lower())) for token in tokenized \n",
    "               if not token.lower() in stopwords.words('english') \n",
    "               if token.isalpha()]\n",
    "\n",
    "        untokenized = \" \".join(cleaned)\n",
    "        preprocessed.append(untokenized)\n",
    "        \n",
    "    return preprocessed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
