{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKSZ10Al0lsa"
   },
   "source": [
    "## Loss Functions\n",
    "\n",
    "In this assignment, we will learn about loss functions. We will use a create a neural network and measure the model's performance using different loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uC8ZyHPq0lsb",
    "outputId": "768dce31-23c6-45eb-c96d-c1b74b553775"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vqKRN1_O0lse"
   },
   "outputs": [],
   "source": [
    "housing = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S5WgUX-I0lsh",
    "outputId": "ee98131f-1192-40fe-a7e3-8353628e3dc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYgIVabm0lsj"
   },
   "source": [
    "We will use the dataset above to predict housing prices using various features about each house. Our first step is to check for missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N_gFN2cu0lsj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0.000000\n",
       "MSSubClass       0.000000\n",
       "MSZoning         0.000000\n",
       "LotFrontage      0.177397\n",
       "LotArea          0.000000\n",
       "Street           0.000000\n",
       "Alley            0.937671\n",
       "LotShape         0.000000\n",
       "LandContour      0.000000\n",
       "Utilities        0.000000\n",
       "LotConfig        0.000000\n",
       "LandSlope        0.000000\n",
       "Neighborhood     0.000000\n",
       "Condition1       0.000000\n",
       "Condition2       0.000000\n",
       "BldgType         0.000000\n",
       "HouseStyle       0.000000\n",
       "OverallQual      0.000000\n",
       "OverallCond      0.000000\n",
       "YearBuilt        0.000000\n",
       "YearRemodAdd     0.000000\n",
       "RoofStyle        0.000000\n",
       "RoofMatl         0.000000\n",
       "Exterior1st      0.000000\n",
       "Exterior2nd      0.000000\n",
       "MasVnrType       0.005479\n",
       "MasVnrArea       0.005479\n",
       "ExterQual        0.000000\n",
       "ExterCond        0.000000\n",
       "Foundation       0.000000\n",
       "BsmtQual         0.025342\n",
       "BsmtCond         0.025342\n",
       "BsmtExposure     0.026027\n",
       "BsmtFinType1     0.025342\n",
       "BsmtFinSF1       0.000000\n",
       "BsmtFinType2     0.026027\n",
       "BsmtFinSF2       0.000000\n",
       "BsmtUnfSF        0.000000\n",
       "TotalBsmtSF      0.000000\n",
       "Heating          0.000000\n",
       "HeatingQC        0.000000\n",
       "CentralAir       0.000000\n",
       "Electrical       0.000685\n",
       "1stFlrSF         0.000000\n",
       "2ndFlrSF         0.000000\n",
       "LowQualFinSF     0.000000\n",
       "GrLivArea        0.000000\n",
       "BsmtFullBath     0.000000\n",
       "BsmtHalfBath     0.000000\n",
       "FullBath         0.000000\n",
       "HalfBath         0.000000\n",
       "BedroomAbvGr     0.000000\n",
       "KitchenAbvGr     0.000000\n",
       "KitchenQual      0.000000\n",
       "TotRmsAbvGrd     0.000000\n",
       "Functional       0.000000\n",
       "Fireplaces       0.000000\n",
       "FireplaceQu      0.472603\n",
       "GarageType       0.055479\n",
       "GarageYrBlt      0.055479\n",
       "GarageFinish     0.055479\n",
       "GarageCars       0.000000\n",
       "GarageArea       0.000000\n",
       "GarageQual       0.055479\n",
       "GarageCond       0.055479\n",
       "PavedDrive       0.000000\n",
       "WoodDeckSF       0.000000\n",
       "OpenPorchSF      0.000000\n",
       "EnclosedPorch    0.000000\n",
       "3SsnPorch        0.000000\n",
       "ScreenPorch      0.000000\n",
       "PoolArea         0.000000\n",
       "PoolQC           0.995205\n",
       "Fence            0.807534\n",
       "MiscFeature      0.963014\n",
       "MiscVal          0.000000\n",
       "MoSold           0.000000\n",
       "YrSold           0.000000\n",
       "SaleType         0.000000\n",
       "SaleCondition    0.000000\n",
       "SalePrice        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer below:\n",
    "housing.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3uqsma30lsl"
   },
   "source": [
    "Remove columns that contain more than 30% of missing data. After removing those columns, remove the rows that contain at least one observation that is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cYdSl4kh0lsm"
   },
   "outputs": [],
   "source": [
    "# Answer below:\n",
    "housing = housing.drop(columns=['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = housing.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dnm4HNYr0lso"
   },
   "source": [
    "There are some categorical variables that contain numeric data and some that do not. Print the type of each column to first see whether there is an issue with misclassification of column type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bKKKIkaC0lsp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1094 entries, 0 to 1459\n",
      "Data columns (total 76 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1094 non-null   int64  \n",
      " 1   MSSubClass     1094 non-null   int64  \n",
      " 2   MSZoning       1094 non-null   object \n",
      " 3   LotFrontage    1094 non-null   float64\n",
      " 4   LotArea        1094 non-null   int64  \n",
      " 5   Street         1094 non-null   object \n",
      " 6   LotShape       1094 non-null   object \n",
      " 7   LandContour    1094 non-null   object \n",
      " 8   Utilities      1094 non-null   object \n",
      " 9   LotConfig      1094 non-null   object \n",
      " 10  LandSlope      1094 non-null   object \n",
      " 11  Neighborhood   1094 non-null   object \n",
      " 12  Condition1     1094 non-null   object \n",
      " 13  Condition2     1094 non-null   object \n",
      " 14  BldgType       1094 non-null   object \n",
      " 15  HouseStyle     1094 non-null   object \n",
      " 16  OverallQual    1094 non-null   int64  \n",
      " 17  OverallCond    1094 non-null   int64  \n",
      " 18  YearBuilt      1094 non-null   int64  \n",
      " 19  YearRemodAdd   1094 non-null   int64  \n",
      " 20  RoofStyle      1094 non-null   object \n",
      " 21  RoofMatl       1094 non-null   object \n",
      " 22  Exterior1st    1094 non-null   object \n",
      " 23  Exterior2nd    1094 non-null   object \n",
      " 24  MasVnrType     1094 non-null   object \n",
      " 25  MasVnrArea     1094 non-null   float64\n",
      " 26  ExterQual      1094 non-null   object \n",
      " 27  ExterCond      1094 non-null   object \n",
      " 28  Foundation     1094 non-null   object \n",
      " 29  BsmtQual       1094 non-null   object \n",
      " 30  BsmtCond       1094 non-null   object \n",
      " 31  BsmtExposure   1094 non-null   object \n",
      " 32  BsmtFinType1   1094 non-null   object \n",
      " 33  BsmtFinSF1     1094 non-null   int64  \n",
      " 34  BsmtFinType2   1094 non-null   object \n",
      " 35  BsmtFinSF2     1094 non-null   int64  \n",
      " 36  BsmtUnfSF      1094 non-null   int64  \n",
      " 37  TotalBsmtSF    1094 non-null   int64  \n",
      " 38  Heating        1094 non-null   object \n",
      " 39  HeatingQC      1094 non-null   object \n",
      " 40  CentralAir     1094 non-null   object \n",
      " 41  Electrical     1094 non-null   object \n",
      " 42  1stFlrSF       1094 non-null   int64  \n",
      " 43  2ndFlrSF       1094 non-null   int64  \n",
      " 44  LowQualFinSF   1094 non-null   int64  \n",
      " 45  GrLivArea      1094 non-null   int64  \n",
      " 46  BsmtFullBath   1094 non-null   int64  \n",
      " 47  BsmtHalfBath   1094 non-null   int64  \n",
      " 48  FullBath       1094 non-null   int64  \n",
      " 49  HalfBath       1094 non-null   int64  \n",
      " 50  BedroomAbvGr   1094 non-null   int64  \n",
      " 51  KitchenAbvGr   1094 non-null   int64  \n",
      " 52  KitchenQual    1094 non-null   object \n",
      " 53  TotRmsAbvGrd   1094 non-null   int64  \n",
      " 54  Functional     1094 non-null   object \n",
      " 55  Fireplaces     1094 non-null   int64  \n",
      " 56  GarageType     1094 non-null   object \n",
      " 57  GarageYrBlt    1094 non-null   float64\n",
      " 58  GarageFinish   1094 non-null   object \n",
      " 59  GarageCars     1094 non-null   int64  \n",
      " 60  GarageArea     1094 non-null   int64  \n",
      " 61  GarageQual     1094 non-null   object \n",
      " 62  GarageCond     1094 non-null   object \n",
      " 63  PavedDrive     1094 non-null   object \n",
      " 64  WoodDeckSF     1094 non-null   int64  \n",
      " 65  OpenPorchSF    1094 non-null   int64  \n",
      " 66  EnclosedPorch  1094 non-null   int64  \n",
      " 67  3SsnPorch      1094 non-null   int64  \n",
      " 68  ScreenPorch    1094 non-null   int64  \n",
      " 69  PoolArea       1094 non-null   int64  \n",
      " 70  MiscVal        1094 non-null   int64  \n",
      " 71  MoSold         1094 non-null   int64  \n",
      " 72  YrSold         1094 non-null   int64  \n",
      " 73  SaleType       1094 non-null   object \n",
      " 74  SaleCondition  1094 non-null   object \n",
      " 75  SalePrice      1094 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(38)\n",
      "memory usage: 658.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Answer below:\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZfA-TZu0lsq"
   },
   "source": [
    "We see that month sold and year sold are not variables that describe a feature of the house. While they do have relevance if we create a model containing a time series element, we will not include them here. Drop these columns. Also, remove the id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lVZUPSWm0lsr"
   },
   "outputs": [],
   "source": [
    "# Answer below\n",
    "housing = housing.drop(columns=['Id', 'MoSold', 'YrSold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OxMXQ8g0lst"
   },
   "source": [
    "Using the information about the column types, identify all the variables that will be converted into dummy variables. Include at least one numeric variable that you think should be converted as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish',\n",
       "       'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
       "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'MiscVal', 'SaleType', 'SaleCondition',\n",
       "       'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WVKWw1hw0lst"
   },
   "outputs": [],
   "source": [
    "# Answer below:\n",
    "dummy_cols = ['MSZoning','Street',\n",
    "            'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
    "            'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
    "            'OverallQual', 'OverallCond',        \n",
    "           'RoofStyle',\n",
    "           'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "           'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
    "           'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC',\n",
    "           'CentralAir', 'Electrical', 'KitchenQual',\n",
    "           'Functional', 'GarageType', 'GarageFinish',\n",
    "           'GarageQual', 'GarageCond', 'PavedDrive',\n",
    "           'SaleType', 'SaleCondition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6wVL2LA0lsv"
   },
   "source": [
    "Convert the columns you selected above into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bORGylTC0lsv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>MSZoning_FV</th>\n",
       "      <th>MSZoning_RH</th>\n",
       "      <th>MSZoning_RL</th>\n",
       "      <th>MSZoning_RM</th>\n",
       "      <th>Street_Pave</th>\n",
       "      <th>LotShape_IR2</th>\n",
       "      <th>LotShape_IR3</th>\n",
       "      <th>LotShape_Reg</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1094 rows Ã— 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      OverallQual  OverallCond  MSZoning_FV  MSZoning_RH  MSZoning_RL  \\\n",
       "0               7            5            0            0            1   \n",
       "1               6            8            0            0            1   \n",
       "2               7            5            0            0            1   \n",
       "3               7            5            0            0            1   \n",
       "4               8            5            0            0            1   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1455            6            5            0            0            1   \n",
       "1456            6            6            0            0            1   \n",
       "1457            7            9            0            0            1   \n",
       "1458            5            6            0            0            1   \n",
       "1459            5            6            0            0            1   \n",
       "\n",
       "      MSZoning_RM  Street_Pave  LotShape_IR2  LotShape_IR3  LotShape_Reg  ...  \\\n",
       "0               0            1             0             0             1  ...   \n",
       "1               0            1             0             0             1  ...   \n",
       "2               0            1             0             0             0  ...   \n",
       "3               0            1             0             0             0  ...   \n",
       "4               0            1             0             0             0  ...   \n",
       "...           ...          ...           ...           ...           ...  ...   \n",
       "1455            0            1             0             0             1  ...   \n",
       "1456            0            1             0             0             1  ...   \n",
       "1457            0            1             0             0             1  ...   \n",
       "1458            0            1             0             0             1  ...   \n",
       "1459            0            1             0             0             1  ...   \n",
       "\n",
       "      SaleType_ConLI  SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0                  0               0             0             0            1   \n",
       "1                  0               0             0             0            1   \n",
       "2                  0               0             0             0            1   \n",
       "3                  0               0             0             0            1   \n",
       "4                  0               0             0             0            1   \n",
       "...              ...             ...           ...           ...          ...   \n",
       "1455               0               0             0             0            1   \n",
       "1456               0               0             0             0            1   \n",
       "1457               0               0             0             0            1   \n",
       "1458               0               0             0             0            1   \n",
       "1459               0               0             0             0            1   \n",
       "\n",
       "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "1455                      0                     0                     0   \n",
       "1456                      0                     0                     0   \n",
       "1457                      0                     0                     0   \n",
       "1458                      0                     0                     0   \n",
       "1459                      0                     0                     0   \n",
       "\n",
       "      SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                        1                      0  \n",
       "1                        1                      0  \n",
       "2                        1                      0  \n",
       "3                        0                      0  \n",
       "4                        1                      0  \n",
       "...                    ...                    ...  \n",
       "1455                     1                      0  \n",
       "1456                     1                      0  \n",
       "1457                     1                      0  \n",
       "1458                     1                      0  \n",
       "1459                     1                      0  \n",
       "\n",
       "[1094 rows x 187 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer below:\n",
    "dummy_df =  pd.get_dummies(housing[dummy_cols], drop_first=True)\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQkbLG0e0lsx"
   },
   "source": [
    "Split the data into train and test with 20% of data in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SivhGDOu0lsx"
   },
   "outputs": [],
   "source": [
    "# Answer below\n",
    "X = housing.drop(columns=dummy_cols)\n",
    "X = X.drop(columns=['SalePrice'])\n",
    "X = pd.concat([X, dummy_df], axis=1)\n",
    "\n",
    "y = housing['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "         ...  \n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1094, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujvHdv2z0lsz"
   },
   "source": [
    "Create a model with 5 layers. The first layer should be a dense layer that takes in the input, the last layer should be of size 1. You determine the remaining layer sizes.\n",
    "\n",
    "Use a linear activation for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5EvTExRC0lsz"
   },
   "outputs": [],
   "source": [
    "# Answer below\n",
    "model = Sequential()\n",
    "\n",
    "# first dense layer\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "# second dense layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# output dense layer\n",
    "model.add(Dense(1, activation='linear')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                2200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,541\n",
      "Trainable params: 2,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blQTwPWz0ls1"
   },
   "source": [
    "Compile the model with the RMSprop optimizer and mean square error loss. Use the MSE as a metric. Set batch size to 100 and epochs to 200. Fit the model and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UjcqV1Zm0ls1"
   },
   "outputs": [],
   "source": [
    "# Answer below:\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 41536688128.0000 - mse: 41536688128.0000 - val_loss: 42877804544.0000 - val_mse: 42877804544.0000\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 41468387328.0000 - mse: 41468387328.0000 - val_loss: 42796306432.0000 - val_mse: 42796306432.0000\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 41380442112.0000 - mse: 41380442112.0000 - val_loss: 42687275008.0000 - val_mse: 42687270912.0000\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 41264836608.0000 - mse: 41264836608.0000 - val_loss: 42544328704.0000 - val_mse: 42544332800.0000\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 41114869760.0000 - mse: 41114869760.0000 - val_loss: 42364882944.0000 - val_mse: 42364882944.0000\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 40927350784.0000 - mse: 40927350784.0000 - val_loss: 42141966336.0000 - val_mse: 42141966336.0000\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 40703492096.0000 - mse: 40703492096.0000 - val_loss: 41883025408.0000 - val_mse: 41883025408.0000\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 40437125120.0000 - mse: 40437125120.0000 - val_loss: 41571418112.0000 - val_mse: 41571418112.0000\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 40118202368.0000 - mse: 40118202368.0000 - val_loss: 41199378432.0000 - val_mse: 41199378432.0000\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 39740837888.0000 - mse: 39740837888.0000 - val_loss: 40766033920.0000 - val_mse: 40766033920.0000\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 39304708096.0000 - mse: 39304704000.0000 - val_loss: 40268349440.0000 - val_mse: 40268345344.0000\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 38796021760.0000 - mse: 38796017664.0000 - val_loss: 39682359296.0000 - val_mse: 39682359296.0000\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 38206300160.0000 - mse: 38206300160.0000 - val_loss: 39006224384.0000 - val_mse: 39006224384.0000\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 37535674368.0000 - mse: 37535674368.0000 - val_loss: 38254444544.0000 - val_mse: 38254444544.0000\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 36780531712.0000 - mse: 36780531712.0000 - val_loss: 37397618688.0000 - val_mse: 37397614592.0000\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 35932057600.0000 - mse: 35932057600.0000 - val_loss: 36442161152.0000 - val_mse: 36442161152.0000\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 34982998016.0000 - mse: 34982998016.0000 - val_loss: 35381993472.0000 - val_mse: 35381993472.0000\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 33930430464.0000 - mse: 33930430464.0000 - val_loss: 34197829632.0000 - val_mse: 34197829632.0000\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 32766251008.0000 - mse: 32766251008.0000 - val_loss: 32908179456.0000 - val_mse: 32908179456.0000\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 31492947968.0000 - mse: 31492947968.0000 - val_loss: 31484203008.0000 - val_mse: 31484203008.0000\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 30102472704.0000 - mse: 30102472704.0000 - val_loss: 29950793728.0000 - val_mse: 29950793728.0000\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28606160896.0000 - mse: 28606160896.0000 - val_loss: 28296034304.0000 - val_mse: 28296034304.0000\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27002357760.0000 - mse: 27002357760.0000 - val_loss: 26543255552.0000 - val_mse: 26543255552.0000\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 25308151808.0000 - mse: 25308151808.0000 - val_loss: 24713897984.0000 - val_mse: 24713897984.0000\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 23568244736.0000 - mse: 23568244736.0000 - val_loss: 22825361408.0000 - val_mse: 22825361408.0000\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 21750366208.0000 - mse: 21750366208.0000 - val_loss: 20863731712.0000 - val_mse: 20863729664.0000\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 19876466688.0000 - mse: 19876466688.0000 - val_loss: 18847930368.0000 - val_mse: 18847930368.0000\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 18024620032.0000 - mse: 18024620032.0000 - val_loss: 16905900032.0000 - val_mse: 16905900032.0000\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 16206221312.0000 - mse: 16206221312.0000 - val_loss: 15002258432.0000 - val_mse: 15002258432.0000\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 14477474816.0000 - mse: 14477474816.0000 - val_loss: 13209041920.0000 - val_mse: 13209043968.0000\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 12895184896.0000 - mse: 12895184896.0000 - val_loss: 11619017728.0000 - val_mse: 11619017728.0000\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 11508433920.0000 - mse: 11508433920.0000 - val_loss: 10346959872.0000 - val_mse: 10346959872.0000\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 10403567616.0000 - mse: 10403567616.0000 - val_loss: 9207680000.0000 - val_mse: 9207678976.0000\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 9426177024.0000 - mse: 9426177024.0000 - val_loss: 8264443392.0000 - val_mse: 8264443392.0000\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8621374464.0000 - mse: 8621374464.0000 - val_loss: 7532760064.0000 - val_mse: 7532760064.0000\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8042577920.0000 - mse: 8042577920.0000 - val_loss: 7036292096.0000 - val_mse: 7036292096.0000\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7727561728.0000 - mse: 7727561728.0000 - val_loss: 6750241280.0000 - val_mse: 6750242304.0000\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7439710208.0000 - mse: 7439710208.0000 - val_loss: 6591286272.0000 - val_mse: 6591286272.0000\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7280114688.0000 - mse: 7280114688.0000 - val_loss: 6463821312.0000 - val_mse: 6463821312.0000\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7187772928.0000 - mse: 7187772928.0000 - val_loss: 6387985408.0000 - val_mse: 6387985408.0000\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7045279232.0000 - mse: 7045279232.0000 - val_loss: 6322865152.0000 - val_mse: 6322866688.0000\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6944997888.0000 - mse: 6944997888.0000 - val_loss: 6268518400.0000 - val_mse: 6268518400.0000\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 6870316544.0000 - mse: 6870316544.0000 - val_loss: 6221925376.0000 - val_mse: 6221925376.0000\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6756818944.0000 - mse: 6756818944.0000 - val_loss: 6183252992.0000 - val_mse: 6183252992.0000\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6691409920.0000 - mse: 6691409920.0000 - val_loss: 6149830656.0000 - val_mse: 6149830656.0000\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6644765696.0000 - mse: 6644765696.0000 - val_loss: 6113764864.0000 - val_mse: 6113764864.0000\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6553778688.0000 - mse: 6553778688.0000 - val_loss: 6065668608.0000 - val_mse: 6065668608.0000\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6450000896.0000 - mse: 6450000896.0000 - val_loss: 6030872064.0000 - val_mse: 6030872064.0000\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 6397911552.0000 - mse: 6397911552.0000 - val_loss: 6000110592.0000 - val_mse: 6000110592.0000\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6337938432.0000 - mse: 6337938432.0000 - val_loss: 5967687680.0000 - val_mse: 5967687680.0000\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6265673728.0000 - mse: 6265673728.0000 - val_loss: 5930362880.0000 - val_mse: 5930362880.0000\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6184472576.0000 - mse: 6184472576.0000 - val_loss: 5900876800.0000 - val_mse: 5900876800.0000\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6102980608.0000 - mse: 6102980608.0000 - val_loss: 5867170304.0000 - val_mse: 5867170304.0000\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 6052599296.0000 - mse: 6052599296.0000 - val_loss: 5825554432.0000 - val_mse: 5825554432.0000\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5959346688.0000 - mse: 5959346688.0000 - val_loss: 5800920064.0000 - val_mse: 5800920064.0000\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5906267648.0000 - mse: 5906267648.0000 - val_loss: 5765943808.0000 - val_mse: 5765943808.0000\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5849847296.0000 - mse: 5849847296.0000 - val_loss: 5726053376.0000 - val_mse: 5726053376.0000\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5789259264.0000 - mse: 5789259264.0000 - val_loss: 5697782272.0000 - val_mse: 5697782272.0000\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5718026752.0000 - mse: 5718026752.0000 - val_loss: 5658359808.0000 - val_mse: 5658359808.0000\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5657683456.0000 - mse: 5657683968.0000 - val_loss: 5636485120.0000 - val_mse: 5636485120.0000\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5593624576.0000 - mse: 5593624576.0000 - val_loss: 5614938112.0000 - val_mse: 5614938112.0000\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5557881344.0000 - mse: 5557881856.0000 - val_loss: 5587493376.0000 - val_mse: 5587493376.0000\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5493559808.0000 - mse: 5493559808.0000 - val_loss: 5553282560.0000 - val_mse: 5553282560.0000\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5448970240.0000 - mse: 5448970240.0000 - val_loss: 5532735488.0000 - val_mse: 5532735488.0000\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5396550656.0000 - mse: 5396550656.0000 - val_loss: 5503823360.0000 - val_mse: 5503823360.0000\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5329709056.0000 - mse: 5329709056.0000 - val_loss: 5472426496.0000 - val_mse: 5472426496.0000\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5265040384.0000 - mse: 5265040384.0000 - val_loss: 5446413312.0000 - val_mse: 5446413312.0000\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5226525184.0000 - mse: 5226525184.0000 - val_loss: 5429724160.0000 - val_mse: 5429724160.0000\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5185728512.0000 - mse: 5185728512.0000 - val_loss: 5399645184.0000 - val_mse: 5399645184.0000\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5113004032.0000 - mse: 5113004032.0000 - val_loss: 5373988352.0000 - val_mse: 5373988352.0000\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5102126592.0000 - mse: 5102126592.0000 - val_loss: 5348961792.0000 - val_mse: 5348961792.0000\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 5032589824.0000 - mse: 5032589824.0000 - val_loss: 5321332736.0000 - val_mse: 5321332736.0000\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4982447104.0000 - mse: 4982447104.0000 - val_loss: 5300489216.0000 - val_mse: 5300489216.0000\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4933127168.0000 - mse: 4933127168.0000 - val_loss: 5277507584.0000 - val_mse: 5277507584.0000\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4890395136.0000 - mse: 4890395136.0000 - val_loss: 5258888704.0000 - val_mse: 5258888704.0000\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4856549376.0000 - mse: 4856549376.0000 - val_loss: 5242946560.0000 - val_mse: 5242946560.0000\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4814906368.0000 - mse: 4814906368.0000 - val_loss: 5234031104.0000 - val_mse: 5234031104.0000\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4772113920.0000 - mse: 4772113920.0000 - val_loss: 5197440512.0000 - val_mse: 5197440512.0000\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4722322944.0000 - mse: 4722322944.0000 - val_loss: 5170249216.0000 - val_mse: 5170249216.0000\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4679750656.0000 - mse: 4679750656.0000 - val_loss: 5164008960.0000 - val_mse: 5164008960.0000\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4642522112.0000 - mse: 4642522112.0000 - val_loss: 5136019456.0000 - val_mse: 5136019456.0000\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4598227456.0000 - mse: 4598227456.0000 - val_loss: 5121795072.0000 - val_mse: 5121795072.0000\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4561945600.0000 - mse: 4561945600.0000 - val_loss: 5089308672.0000 - val_mse: 5089308672.0000\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4533069824.0000 - mse: 4533069824.0000 - val_loss: 5065905664.0000 - val_mse: 5065905664.0000\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4487724544.0000 - mse: 4487724544.0000 - val_loss: 5057134080.0000 - val_mse: 5057134080.0000\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4446659072.0000 - mse: 4446659072.0000 - val_loss: 5031600128.0000 - val_mse: 5031600128.0000\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4409977344.0000 - mse: 4409977344.0000 - val_loss: 5032660480.0000 - val_mse: 5032660480.0000\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4374569472.0000 - mse: 4374569472.0000 - val_loss: 4993459200.0000 - val_mse: 4993459200.0000\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4329991680.0000 - mse: 4329991680.0000 - val_loss: 4981107712.0000 - val_mse: 4981107712.0000\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4318810112.0000 - mse: 4318810112.0000 - val_loss: 4965554688.0000 - val_mse: 4965554688.0000\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4263420672.0000 - mse: 4263420672.0000 - val_loss: 4957346304.0000 - val_mse: 4957346304.0000\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4236429312.0000 - mse: 4236429312.0000 - val_loss: 4956803584.0000 - val_mse: 4956803584.0000\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4206403072.0000 - mse: 4206403584.0000 - val_loss: 4955014144.0000 - val_mse: 4955014144.0000\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4189301504.0000 - mse: 4189300992.0000 - val_loss: 4905329664.0000 - val_mse: 4905329664.0000\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4145779200.0000 - mse: 4145779200.0000 - val_loss: 4866479616.0000 - val_mse: 4866479616.0000\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4105484032.0000 - mse: 4105484032.0000 - val_loss: 4861528064.0000 - val_mse: 4861528064.0000\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4081843200.0000 - mse: 4081843200.0000 - val_loss: 4837017600.0000 - val_mse: 4837017600.0000\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 4056811008.0000 - mse: 4056811008.0000 - val_loss: 4832359424.0000 - val_mse: 4832359424.0000\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4009458688.0000 - mse: 4009458688.0000 - val_loss: 4851256832.0000 - val_mse: 4851256832.0000\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3998913536.0000 - mse: 3998913536.0000 - val_loss: 4810456576.0000 - val_mse: 4810456576.0000\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3971435264.0000 - mse: 3971435264.0000 - val_loss: 4793885184.0000 - val_mse: 4793885184.0000\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3922451968.0000 - mse: 3922451968.0000 - val_loss: 4783116288.0000 - val_mse: 4783116288.0000\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3899457280.0000 - mse: 3899457280.0000 - val_loss: 4764075008.0000 - val_mse: 4764075008.0000\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3882338048.0000 - mse: 3882338048.0000 - val_loss: 4754973184.0000 - val_mse: 4754973184.0000\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3846245120.0000 - mse: 3846245120.0000 - val_loss: 4727667200.0000 - val_mse: 4727667200.0000\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3828296960.0000 - mse: 3828296960.0000 - val_loss: 4719097344.0000 - val_mse: 4719097344.0000\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3791803136.0000 - mse: 3791803136.0000 - val_loss: 4715489280.0000 - val_mse: 4715489280.0000\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3764236288.0000 - mse: 3764236288.0000 - val_loss: 4694206976.0000 - val_mse: 4694206976.0000\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3736107264.0000 - mse: 3736106752.0000 - val_loss: 4687140352.0000 - val_mse: 4687140352.0000\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3704833024.0000 - mse: 3704833024.0000 - val_loss: 4662919680.0000 - val_mse: 4662919680.0000\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3698855424.0000 - mse: 3698855424.0000 - val_loss: 4635511296.0000 - val_mse: 4635511296.0000\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3654214656.0000 - mse: 3654214656.0000 - val_loss: 4615761920.0000 - val_mse: 4615761920.0000\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3630108672.0000 - mse: 3630108672.0000 - val_loss: 4601432064.0000 - val_mse: 4601432064.0000\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3603684352.0000 - mse: 3603684352.0000 - val_loss: 4599099904.0000 - val_mse: 4599099904.0000\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3581028096.0000 - mse: 3581028096.0000 - val_loss: 4598003200.0000 - val_mse: 4598003200.0000\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3562443264.0000 - mse: 3562443264.0000 - val_loss: 4603125760.0000 - val_mse: 4603125760.0000\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3524493056.0000 - mse: 3524493056.0000 - val_loss: 4553230848.0000 - val_mse: 4553230848.0000\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3511960320.0000 - mse: 3511960320.0000 - val_loss: 4545222144.0000 - val_mse: 4545222144.0000\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3473909248.0000 - mse: 3473909248.0000 - val_loss: 4542716928.0000 - val_mse: 4542716928.0000\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3443766016.0000 - mse: 3443766016.0000 - val_loss: 4564375552.0000 - val_mse: 4564375552.0000\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3417472768.0000 - mse: 3417472768.0000 - val_loss: 4495945216.0000 - val_mse: 4495945216.0000\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3404671744.0000 - mse: 3404671744.0000 - val_loss: 4496913920.0000 - val_mse: 4496913920.0000\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3371933952.0000 - mse: 3371933952.0000 - val_loss: 4481632768.0000 - val_mse: 4481632768.0000\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3338473472.0000 - mse: 3338473472.0000 - val_loss: 4503691264.0000 - val_mse: 4503691264.0000\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3309181184.0000 - mse: 3309181184.0000 - val_loss: 4441786368.0000 - val_mse: 4441786368.0000\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3300504064.0000 - mse: 3300504064.0000 - val_loss: 4462312960.0000 - val_mse: 4462312960.0000\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3268430080.0000 - mse: 3268430080.0000 - val_loss: 4450856960.0000 - val_mse: 4450856960.0000\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3246221312.0000 - mse: 3246221056.0000 - val_loss: 4427060736.0000 - val_mse: 4427060736.0000\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3224916224.0000 - mse: 3224916224.0000 - val_loss: 4408689152.0000 - val_mse: 4408689152.0000\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3198020608.0000 - mse: 3198020608.0000 - val_loss: 4418969600.0000 - val_mse: 4418969600.0000\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3180013824.0000 - mse: 3180013824.0000 - val_loss: 4403057152.0000 - val_mse: 4403057152.0000\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3150864896.0000 - mse: 3150864896.0000 - val_loss: 4364213248.0000 - val_mse: 4364213248.0000\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3126325504.0000 - mse: 3126325760.0000 - val_loss: 4390304256.0000 - val_mse: 4390304256.0000\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3111655936.0000 - mse: 3111655936.0000 - val_loss: 4375027712.0000 - val_mse: 4375027712.0000\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3089193472.0000 - mse: 3089193472.0000 - val_loss: 4356268544.0000 - val_mse: 4356268544.0000\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3060467968.0000 - mse: 3060467968.0000 - val_loss: 4326862848.0000 - val_mse: 4326862848.0000\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3033408256.0000 - mse: 3033408256.0000 - val_loss: 4333010944.0000 - val_mse: 4333010944.0000\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3006435840.0000 - mse: 3006435840.0000 - val_loss: 4339380224.0000 - val_mse: 4339380224.0000\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2988999168.0000 - mse: 2988999168.0000 - val_loss: 4306488320.0000 - val_mse: 4306488320.0000\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2961753344.0000 - mse: 2961753344.0000 - val_loss: 4294574592.0000 - val_mse: 4294574592.0000\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2940809984.0000 - mse: 2940809984.0000 - val_loss: 4274262016.0000 - val_mse: 4274262016.0000\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2910103296.0000 - mse: 2910103296.0000 - val_loss: 4263247616.0000 - val_mse: 4263247616.0000\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2887593216.0000 - mse: 2887593216.0000 - val_loss: 4252600320.0000 - val_mse: 4252600320.0000\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2856648960.0000 - mse: 2856648960.0000 - val_loss: 4252344320.0000 - val_mse: 4252344320.0000\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2849646080.0000 - mse: 2849646080.0000 - val_loss: 4264357376.0000 - val_mse: 4264357376.0000\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2814081024.0000 - mse: 2814081024.0000 - val_loss: 4226843392.0000 - val_mse: 4226843392.0000\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 2808439552.0000 - mse: 2808439552.0000 - val_loss: 4225131264.0000 - val_mse: 4225131264.0000\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2780103936.0000 - mse: 2780103936.0000 - val_loss: 4198801408.0000 - val_mse: 4198801408.0000\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2746010880.0000 - mse: 2746010880.0000 - val_loss: 4157455104.0000 - val_mse: 4157455104.0000\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2747753472.0000 - mse: 2747753472.0000 - val_loss: 4196568320.0000 - val_mse: 4196568320.0000\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2711614720.0000 - mse: 2711614720.0000 - val_loss: 4170945024.0000 - val_mse: 4170945024.0000\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2687500800.0000 - mse: 2687500800.0000 - val_loss: 4156200448.0000 - val_mse: 4156200448.0000\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2679581440.0000 - mse: 2679581440.0000 - val_loss: 4142713344.0000 - val_mse: 4142713344.0000\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2649765888.0000 - mse: 2649765888.0000 - val_loss: 4147606272.0000 - val_mse: 4147606272.0000\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2633530624.0000 - mse: 2633530624.0000 - val_loss: 4113680640.0000 - val_mse: 4113680640.0000\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2619765248.0000 - mse: 2619765248.0000 - val_loss: 4129705472.0000 - val_mse: 4129705472.0000\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2591151104.0000 - mse: 2591151104.0000 - val_loss: 4145573888.0000 - val_mse: 4145573888.0000\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2572414976.0000 - mse: 2572414976.0000 - val_loss: 4089843456.0000 - val_mse: 4089843456.0000\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2553877248.0000 - mse: 2553877248.0000 - val_loss: 4065210112.0000 - val_mse: 4065209856.0000\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2547261440.0000 - mse: 2547261696.0000 - val_loss: 4106080256.0000 - val_mse: 4106080256.0000\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2520445952.0000 - mse: 2520445952.0000 - val_loss: 4067089920.0000 - val_mse: 4067089920.0000\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2497411328.0000 - mse: 2497411328.0000 - val_loss: 4023081984.0000 - val_mse: 4023081984.0000\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2500333056.0000 - mse: 2500333056.0000 - val_loss: 4041589504.0000 - val_mse: 4041589504.0000\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2469250816.0000 - mse: 2469250816.0000 - val_loss: 4058899456.0000 - val_mse: 4058899456.0000\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2447034880.0000 - mse: 2447034880.0000 - val_loss: 4102103808.0000 - val_mse: 4102103808.0000\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2440112640.0000 - mse: 2440112640.0000 - val_loss: 4043588864.0000 - val_mse: 4043589120.0000\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2421713152.0000 - mse: 2421713152.0000 - val_loss: 4032857600.0000 - val_mse: 4032857600.0000\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2405009152.0000 - mse: 2405009152.0000 - val_loss: 4073439744.0000 - val_mse: 4073439744.0000\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2390528768.0000 - mse: 2390528768.0000 - val_loss: 4009497088.0000 - val_mse: 4009496576.0000\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2372482304.0000 - mse: 2372482304.0000 - val_loss: 4004488960.0000 - val_mse: 4004488704.0000\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2353462272.0000 - mse: 2353462272.0000 - val_loss: 4062326272.0000 - val_mse: 4062326272.0000\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2350884608.0000 - mse: 2350884864.0000 - val_loss: 3984308736.0000 - val_mse: 3984308736.0000\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2321301760.0000 - mse: 2321301760.0000 - val_loss: 4070594304.0000 - val_mse: 4070594560.0000\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2310265088.0000 - mse: 2310265088.0000 - val_loss: 4009570048.0000 - val_mse: 4009570048.0000\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2304711680.0000 - mse: 2304711680.0000 - val_loss: 3997966336.0000 - val_mse: 3997966336.0000\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2286398208.0000 - mse: 2286398208.0000 - val_loss: 3976419840.0000 - val_mse: 3976419840.0000\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2269661696.0000 - mse: 2269661696.0000 - val_loss: 3956584192.0000 - val_mse: 3956584192.0000\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2266206976.0000 - mse: 2266206976.0000 - val_loss: 3975642112.0000 - val_mse: 3975642112.0000\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2260704512.0000 - mse: 2260704512.0000 - val_loss: 3963814144.0000 - val_mse: 3963814144.0000\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2241469184.0000 - mse: 2241469184.0000 - val_loss: 3968766720.0000 - val_mse: 3968766720.0000\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2235860736.0000 - mse: 2235860736.0000 - val_loss: 3967240960.0000 - val_mse: 3967240960.0000\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2210446848.0000 - mse: 2210446848.0000 - val_loss: 4012554496.0000 - val_mse: 4012554496.0000\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2205519360.0000 - mse: 2205519360.0000 - val_loss: 3950745088.0000 - val_mse: 3950745088.0000\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2212773376.0000 - mse: 2212773376.0000 - val_loss: 3991993344.0000 - val_mse: 3991993344.0000\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2185971456.0000 - mse: 2185971456.0000 - val_loss: 3976879616.0000 - val_mse: 3976879616.0000\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2172619264.0000 - mse: 2172619264.0000 - val_loss: 3964034560.0000 - val_mse: 3964034560.0000\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2166331904.0000 - mse: 2166331904.0000 - val_loss: 4007951616.0000 - val_mse: 4007951616.0000\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2150754048.0000 - mse: 2150754048.0000 - val_loss: 3990838016.0000 - val_mse: 3990838016.0000\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2146197248.0000 - mse: 2146197248.0000 - val_loss: 3936407552.0000 - val_mse: 3936407552.0000\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2144925696.0000 - mse: 2144925696.0000 - val_loss: 3986907904.0000 - val_mse: 3986907904.0000\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2118324224.0000 - mse: 2118324224.0000 - val_loss: 3995767808.0000 - val_mse: 3995767808.0000\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2122849152.0000 - mse: 2122849152.0000 - val_loss: 4013721600.0000 - val_mse: 4013721856.0000\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2109056896.0000 - mse: 2109056896.0000 - val_loss: 4047325696.0000 - val_mse: 4047325696.0000\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2105099264.0000 - mse: 2105099264.0000 - val_loss: 4017829632.0000 - val_mse: 4017829632.0000\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2087578112.0000 - mse: 2087578112.0000 - val_loss: 4028206848.0000 - val_mse: 4028206848.0000\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 2073298944.0000 - mse: 2073298944.0000 - val_loss: 4125538816.0000 - val_mse: 4125539072.0000\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2077141632.0000 - mse: 2077141248.0000 - val_loss: 4028809728.0000 - val_mse: 4028809728.0000\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2059600384.0000 - mse: 2059600384.0000 - val_loss: 4037110016.0000 - val_mse: 4037110016.0000\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2049618816.0000 - mse: 2049618688.0000 - val_loss: 3979313408.0000 - val_mse: 3979313408.0000\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 2037496576.0000 - mse: 2037496704.0000 - val_loss: 4046970624.0000 - val_mse: 4046970624.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x273d527d788>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pD1byILV0ls3"
   },
   "source": [
    "Next, do the same but with mean absolute error loss. Use both MSE and MAE as metrics. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UjcqV1Zm0ls1"
   },
   "outputs": [],
   "source": [
    "# Answer below:\n",
    "model.compile(optimizer='rmsprop', loss='mean_absolute_error', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 29980.2520 - mse: 2060468608.0000 - mae: 29980.2520 - val_loss: 32625.1270 - val_mse: 3984685824.0000 - val_mae: 32625.1270\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29803.9648 - mse: 2053948928.0000 - mae: 29803.9648 - val_loss: 32536.8340 - val_mse: 3959368704.0000 - val_mae: 32536.8340\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29706.8574 - mse: 2053415168.0000 - mae: 29706.8574 - val_loss: 32438.2520 - val_mse: 3966093568.0000 - val_mae: 32438.2520\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29638.1934 - mse: 2038995840.0000 - mae: 29638.1934 - val_loss: 32352.9570 - val_mse: 3978127104.0000 - val_mae: 32352.9570\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29573.4062 - mse: 2040625920.0000 - mae: 29573.4062 - val_loss: 32297.7344 - val_mse: 3998764288.0000 - val_mae: 32297.7344\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29495.8066 - mse: 2007340928.0000 - mae: 29495.8066 - val_loss: 32334.0273 - val_mse: 3977591040.0000 - val_mae: 32334.0273\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29531.5000 - mse: 2047113472.0000 - mae: 29531.5000 - val_loss: 32248.9512 - val_mse: 4037465344.0000 - val_mae: 32248.9512\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29483.5254 - mse: 2002339968.0000 - mae: 29483.5254 - val_loss: 32134.4824 - val_mse: 3991663872.0000 - val_mae: 32134.4824\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29341.7637 - mse: 2005189248.0000 - mae: 29341.7637 - val_loss: 32049.5098 - val_mse: 4008435712.0000 - val_mae: 32049.5098\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29343.2168 - mse: 2003865600.0000 - mae: 29343.2168 - val_loss: 32036.3809 - val_mse: 4000260608.0000 - val_mae: 32036.3809\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29244.1836 - mse: 1989584640.0000 - mae: 29244.1836 - val_loss: 32040.3730 - val_mse: 4002043648.0000 - val_mae: 32040.3730\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29178.2910 - mse: 1994601984.0000 - mae: 29178.2910 - val_loss: 32017.6035 - val_mse: 4073268992.0000 - val_mae: 32017.6035\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29146.1777 - mse: 1973390976.0000 - mae: 29146.1777 - val_loss: 31857.7988 - val_mse: 4031992064.0000 - val_mae: 31857.7988\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29062.7480 - mse: 1970851072.0000 - mae: 29062.7480 - val_loss: 31851.4336 - val_mse: 4021518848.0000 - val_mae: 31851.4336\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 29016.7305 - mse: 1957318144.0000 - mae: 29016.7305 - val_loss: 31773.5098 - val_mse: 4047290368.0000 - val_mae: 31773.5098\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28906.5098 - mse: 1954703104.0000 - mae: 28906.5098 - val_loss: 31842.7852 - val_mse: 4025928448.0000 - val_mae: 31842.7852\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28926.6074 - mse: 1950022016.0000 - mae: 28926.6074 - val_loss: 31718.6523 - val_mse: 4047770112.0000 - val_mae: 31718.6523\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28929.0645 - mse: 1947024384.0000 - mae: 28929.0645 - val_loss: 31695.1719 - val_mse: 4053213696.0000 - val_mae: 31695.1719\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28859.5703 - mse: 1937210624.0000 - mae: 28859.5703 - val_loss: 31696.6523 - val_mse: 4054487552.0000 - val_mae: 31696.6504\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28828.2402 - mse: 1949083776.0000 - mae: 28828.2402 - val_loss: 31616.5977 - val_mse: 4076434176.0000 - val_mae: 31616.5977\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28719.2578 - mse: 1922063488.0000 - mae: 28719.2578 - val_loss: 31688.5781 - val_mse: 4061011968.0000 - val_mae: 31688.5781\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28771.8242 - mse: 1924181888.0000 - mae: 28771.8242 - val_loss: 31509.4590 - val_mse: 4108367872.0000 - val_mae: 31509.4590\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28673.1562 - mse: 1921088640.0000 - mae: 28673.1562 - val_loss: 31553.8535 - val_mse: 4088009984.0000 - val_mae: 31553.8535\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28642.3301 - mse: 1902221312.0000 - mae: 28642.3301 - val_loss: 31679.3477 - val_mse: 4066667776.0000 - val_mae: 31679.3477\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28641.7930 - mse: 1923511168.0000 - mae: 28641.7949 - val_loss: 31453.4180 - val_mse: 4123059968.0000 - val_mae: 31453.4180\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28580.9668 - mse: 1901558272.0000 - mae: 28580.9668 - val_loss: 31411.9434 - val_mse: 4139698432.0000 - val_mae: 31411.9434\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28536.4277 - mse: 1898454912.0000 - mae: 28536.4277 - val_loss: 31565.6641 - val_mse: 4093841920.0000 - val_mae: 31565.6641\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28462.9219 - mse: 1896524800.0000 - mae: 28462.9180 - val_loss: 31606.7520 - val_mse: 4093136128.0000 - val_mae: 31606.7520\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 28448.8379 - mse: 1892534016.0000 - mae: 28448.8379 - val_loss: 31315.7012 - val_mse: 4178890752.0000 - val_mae: 31315.7012\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28546.6855 - mse: 1906001152.0000 - mae: 28546.6875 - val_loss: 31309.7891 - val_mse: 4190221312.0000 - val_mae: 31309.7891\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28413.6699 - mse: 1883749120.0000 - mae: 28413.6699 - val_loss: 31311.7324 - val_mse: 4174048768.0000 - val_mae: 31311.7324\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28371.2520 - mse: 1883843200.0000 - mae: 28371.2520 - val_loss: 31337.9688 - val_mse: 4155598592.0000 - val_mae: 31337.9688\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28321.1953 - mse: 1868313216.0000 - mae: 28321.1953 - val_loss: 31359.8457 - val_mse: 4142772480.0000 - val_mae: 31359.8457\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28360.2871 - mse: 1876110336.0000 - mae: 28360.2871 - val_loss: 31232.8398 - val_mse: 4211968000.0000 - val_mae: 31232.8398\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28277.5742 - mse: 1865269888.0000 - mae: 28277.5742 - val_loss: 31234.8066 - val_mse: 4241191680.0000 - val_mae: 31234.8066\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28346.7695 - mse: 1869201408.0000 - mae: 28346.7695 - val_loss: 31230.0957 - val_mse: 4215983616.0000 - val_mae: 31230.0957\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28318.5879 - mse: 1867782272.0000 - mae: 28318.5879 - val_loss: 31221.9434 - val_mse: 4224386048.0000 - val_mae: 31221.9434\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28187.2363 - mse: 1846087168.0000 - mae: 28187.2363 - val_loss: 31301.9824 - val_mse: 4174802176.0000 - val_mae: 31301.9824\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28182.5352 - mse: 1855267200.0000 - mae: 28182.5371 - val_loss: 31226.5234 - val_mse: 4199872512.0000 - val_mae: 31226.5234\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28186.9434 - mse: 1840468480.0000 - mae: 28186.9434 - val_loss: 31231.4414 - val_mse: 4203358464.0000 - val_mae: 31231.4414\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28156.8008 - mse: 1845531008.0000 - mae: 28156.8008 - val_loss: 31167.5508 - val_mse: 4220326656.0000 - val_mae: 31167.5508\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28110.7656 - mse: 1842608384.0000 - mae: 28110.7656 - val_loss: 31202.4316 - val_mse: 4212680704.0000 - val_mae: 31202.4316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28201.9062 - mse: 1852209792.0000 - mae: 28201.9062 - val_loss: 31101.8613 - val_mse: 4261448448.0000 - val_mae: 31101.8613\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28105.3027 - mse: 1844746880.0000 - mae: 28105.3027 - val_loss: 31132.8672 - val_mse: 4235287296.0000 - val_mae: 31132.8672\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28153.2910 - mse: 1861120256.0000 - mae: 28153.2910 - val_loss: 31087.7891 - val_mse: 4308643328.0000 - val_mae: 31087.7891\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28074.6895 - mse: 1832032128.0000 - mae: 28074.6895 - val_loss: 31140.1797 - val_mse: 4229778944.0000 - val_mae: 31140.1797\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28065.1836 - mse: 1838765184.0000 - mae: 28065.1836 - val_loss: 31090.5352 - val_mse: 4257810176.0000 - val_mae: 31090.5352\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28041.1387 - mse: 1841362432.0000 - mae: 28041.1387 - val_loss: 31175.5488 - val_mse: 4223026944.0000 - val_mae: 31175.5488\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28050.5605 - mse: 1849766400.0000 - mae: 28050.5605 - val_loss: 31087.6758 - val_mse: 4258395392.0000 - val_mae: 31087.6758\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28051.1016 - mse: 1842199296.0000 - mae: 28051.1016 - val_loss: 31027.5977 - val_mse: 4291478272.0000 - val_mae: 31027.5977\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28066.9883 - mse: 1829466880.0000 - mae: 28066.9883 - val_loss: 30998.8906 - val_mse: 4296155136.0000 - val_mae: 30998.8906\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27944.4434 - mse: 1831967616.0000 - mae: 27944.4434 - val_loss: 30952.3008 - val_mse: 4330412544.0000 - val_mae: 30952.3008\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28091.7402 - mse: 1828132480.0000 - mae: 28091.7402 - val_loss: 31091.2520 - val_mse: 4255865856.0000 - val_mae: 31091.2520\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27954.6270 - mse: 1837953792.0000 - mae: 27954.6270 - val_loss: 30978.8750 - val_mse: 4292857344.0000 - val_mae: 30978.8750\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27893.8125 - mse: 1820985600.0000 - mae: 27893.8125 - val_loss: 31402.9375 - val_mse: 4211419392.0000 - val_mae: 31402.9375\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27934.2305 - mse: 1828144000.0000 - mae: 27934.2305 - val_loss: 31173.2305 - val_mse: 4240407552.0000 - val_mae: 31173.2305\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27881.0703 - mse: 1816335872.0000 - mae: 27881.0703 - val_loss: 30949.5527 - val_mse: 4429423104.0000 - val_mae: 30949.5527\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27869.0898 - mse: 1820733440.0000 - mae: 27869.0898 - val_loss: 31094.3105 - val_mse: 4261261056.0000 - val_mae: 31094.3105\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 28080.6426 - mse: 1844900096.0000 - mae: 28080.6426 - val_loss: 31011.3359 - val_mse: 4282490112.0000 - val_mae: 31011.3359\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27725.3945 - mse: 1808338048.0000 - mae: 27725.3945 - val_loss: 30876.0840 - val_mse: 4432730112.0000 - val_mae: 30876.0840\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27877.0625 - mse: 1823814016.0000 - mae: 27877.0625 - val_loss: 31156.5820 - val_mse: 4260412416.0000 - val_mae: 31156.5820\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27776.6699 - mse: 1836486912.0000 - mae: 27776.6699 - val_loss: 30842.5645 - val_mse: 4452416000.0000 - val_mae: 30842.5645\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27946.6406 - mse: 1844291456.0000 - mae: 27946.6406 - val_loss: 30947.8457 - val_mse: 4312068096.0000 - val_mae: 30947.8457\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27874.0977 - mse: 1818039808.0000 - mae: 27874.0977 - val_loss: 30852.6230 - val_mse: 4337077760.0000 - val_mae: 30852.6230\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27898.4277 - mse: 1817901568.0000 - mae: 27898.4277 - val_loss: 30808.6582 - val_mse: 4368581120.0000 - val_mae: 30808.6582\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27887.1250 - mse: 1815000704.0000 - mae: 27887.1250 - val_loss: 30788.1543 - val_mse: 4389491200.0000 - val_mae: 30788.1543\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27866.0293 - mse: 1816163584.0000 - mae: 27866.0293 - val_loss: 30872.5938 - val_mse: 4334460416.0000 - val_mae: 30872.5938\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27781.1973 - mse: 1803841536.0000 - mae: 27781.1973 - val_loss: 31027.9980 - val_mse: 4292133376.0000 - val_mae: 31027.9980\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27926.1074 - mse: 1838862848.0000 - mae: 27926.1074 - val_loss: 30830.4219 - val_mse: 4350871552.0000 - val_mae: 30830.4219\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27757.6406 - mse: 1812087936.0000 - mae: 27757.6406 - val_loss: 30772.9141 - val_mse: 4423019520.0000 - val_mae: 30772.9141\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27833.2852 - mse: 1813122176.0000 - mae: 27833.2852 - val_loss: 30778.3887 - val_mse: 4375970304.0000 - val_mae: 30778.3887\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27723.9844 - mse: 1801860736.0000 - mae: 27723.9844 - val_loss: 30990.4707 - val_mse: 4306287616.0000 - val_mae: 30990.4707\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27822.1641 - mse: 1810546688.0000 - mae: 27822.1641 - val_loss: 30745.0215 - val_mse: 4410614784.0000 - val_mae: 30745.0215\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27740.5312 - mse: 1806199424.0000 - mae: 27740.5312 - val_loss: 30741.9180 - val_mse: 4418633216.0000 - val_mae: 30741.9180\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27710.0039 - mse: 1812175744.0000 - mae: 27710.0039 - val_loss: 30765.9785 - val_mse: 4503607296.0000 - val_mae: 30765.9785\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27793.6094 - mse: 1809527296.0000 - mae: 27793.6094 - val_loss: 30721.7148 - val_mse: 4459196416.0000 - val_mae: 30721.7148\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27786.8145 - mse: 1806796800.0000 - mae: 27786.8145 - val_loss: 30791.5430 - val_mse: 4360931328.0000 - val_mae: 30791.5430\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27701.0117 - mse: 1804872704.0000 - mae: 27701.0117 - val_loss: 30754.1387 - val_mse: 4380174848.0000 - val_mae: 30754.1387\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27700.8027 - mse: 1798847872.0000 - mae: 27700.8027 - val_loss: 30790.6133 - val_mse: 4372008960.0000 - val_mae: 30790.6133\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27739.1699 - mse: 1798713472.0000 - mae: 27739.1699 - val_loss: 30692.8418 - val_mse: 4412645888.0000 - val_mae: 30692.8418\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27628.3145 - mse: 1795308160.0000 - mae: 27628.3145 - val_loss: 31039.1992 - val_mse: 4298552832.0000 - val_mae: 31039.1992\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27688.6074 - mse: 1818859392.0000 - mae: 27688.6074 - val_loss: 30654.2383 - val_mse: 4436432896.0000 - val_mae: 30654.2383\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27734.7363 - mse: 1809236352.0000 - mae: 27734.7363 - val_loss: 30672.1641 - val_mse: 4409383936.0000 - val_mae: 30672.1641\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27632.7305 - mse: 1790859904.0000 - mae: 27632.7305 - val_loss: 30908.7266 - val_mse: 4315765248.0000 - val_mae: 30908.7266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27817.4336 - mse: 1819808256.0000 - mae: 27817.4336 - val_loss: 30611.5684 - val_mse: 4425522176.0000 - val_mae: 30611.5684\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27707.3594 - mse: 1800754560.0000 - mae: 27707.3594 - val_loss: 30709.8457 - val_mse: 4374119936.0000 - val_mae: 30709.8457\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27667.7734 - mse: 1799493120.0000 - mae: 27667.7734 - val_loss: 30694.0801 - val_mse: 4379306496.0000 - val_mae: 30694.0801\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27651.7988 - mse: 1798628224.0000 - mae: 27651.7988 - val_loss: 30594.5996 - val_mse: 4459112960.0000 - val_mae: 30594.5996\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27640.3086 - mse: 1806903808.0000 - mae: 27640.3086 - val_loss: 30610.3203 - val_mse: 4465577472.0000 - val_mae: 30610.3203\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27596.0410 - mse: 1796699904.0000 - mae: 27596.0410 - val_loss: 31072.2559 - val_mse: 4303326720.0000 - val_mae: 31072.2559\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27735.9648 - mse: 1809957248.0000 - mae: 27735.9648 - val_loss: 30804.8203 - val_mse: 4335467008.0000 - val_mae: 30804.8203\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27589.9707 - mse: 1796315904.0000 - mae: 27589.9707 - val_loss: 30744.1270 - val_mse: 4358827008.0000 - val_mae: 30744.1270\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27644.6309 - mse: 1802449920.0000 - mae: 27644.6309 - val_loss: 30653.2051 - val_mse: 4398689280.0000 - val_mae: 30653.2051\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27594.4141 - mse: 1792667136.0000 - mae: 27594.4141 - val_loss: 30567.7148 - val_mse: 4453465600.0000 - val_mae: 30567.7148\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27688.6289 - mse: 1793722752.0000 - mae: 27688.6289 - val_loss: 30654.9844 - val_mse: 4400343552.0000 - val_mae: 30654.9844\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27597.3574 - mse: 1793788416.0000 - mae: 27597.3574 - val_loss: 30578.4102 - val_mse: 4480509440.0000 - val_mae: 30578.4102\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27579.4180 - mse: 1788097408.0000 - mae: 27579.4180 - val_loss: 30602.4238 - val_mse: 4427423232.0000 - val_mae: 30602.4238\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27559.1035 - mse: 1794461184.0000 - mae: 27559.1035 - val_loss: 30541.7754 - val_mse: 4453304832.0000 - val_mae: 30541.7754\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27598.2422 - mse: 1814330368.0000 - mae: 27598.2422 - val_loss: 30513.6602 - val_mse: 4477206528.0000 - val_mae: 30513.6602\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27596.8223 - mse: 1799244416.0000 - mae: 27596.8223 - val_loss: 30586.2148 - val_mse: 4416702464.0000 - val_mae: 30586.2148\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27589.3164 - mse: 1795872256.0000 - mae: 27589.3164 - val_loss: 30547.1309 - val_mse: 4504072704.0000 - val_mae: 30547.1309\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27551.6465 - mse: 1805094656.0000 - mae: 27551.6465 - val_loss: 30562.0176 - val_mse: 4427348992.0000 - val_mae: 30562.0176\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27663.7715 - mse: 1804798464.0000 - mae: 27663.7715 - val_loss: 30529.8398 - val_mse: 4482460160.0000 - val_mae: 30529.8398\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27563.0488 - mse: 1789309568.0000 - mae: 27563.0488 - val_loss: 30735.7754 - val_mse: 4350872064.0000 - val_mae: 30735.7754\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27604.9844 - mse: 1798000512.0000 - mae: 27604.9844 - val_loss: 30621.7305 - val_mse: 4387674112.0000 - val_mae: 30621.7305\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27526.5508 - mse: 1794774144.0000 - mae: 27526.5508 - val_loss: 30555.8340 - val_mse: 4423120896.0000 - val_mae: 30555.8340\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27495.4375 - mse: 1791249536.0000 - mae: 27495.4375 - val_loss: 30933.9453 - val_mse: 4323709440.0000 - val_mae: 30933.9453\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27548.5527 - mse: 1795619200.0000 - mae: 27548.5527 - val_loss: 30564.2617 - val_mse: 4410905600.0000 - val_mae: 30564.2617\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27597.3008 - mse: 1780834944.0000 - mae: 27597.3008 - val_loss: 30785.2383 - val_mse: 4345781760.0000 - val_mae: 30785.2383\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27503.1621 - mse: 1799785984.0000 - mae: 27503.1621 - val_loss: 30488.4492 - val_mse: 4474187264.0000 - val_mae: 30488.4492\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27601.4883 - mse: 1787225600.0000 - mae: 27601.4883 - val_loss: 30519.0664 - val_mse: 4431919616.0000 - val_mae: 30519.0664\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27494.0078 - mse: 1795578240.0000 - mae: 27494.0078 - val_loss: 30487.0527 - val_mse: 4437755904.0000 - val_mae: 30487.0527\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27543.7422 - mse: 1782028800.0000 - mae: 27543.7422 - val_loss: 30618.9609 - val_mse: 4383449600.0000 - val_mae: 30618.9609\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27472.7012 - mse: 1781682048.0000 - mae: 27472.7012 - val_loss: 30477.1875 - val_mse: 4494595584.0000 - val_mae: 30477.1875\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27504.8730 - mse: 1794778368.0000 - mae: 27504.8730 - val_loss: 30762.5117 - val_mse: 4349520896.0000 - val_mae: 30762.5117\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27523.4219 - mse: 1787576960.0000 - mae: 27523.4219 - val_loss: 30522.7461 - val_mse: 4415148032.0000 - val_mae: 30522.7461\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27402.2656 - mse: 1792836352.0000 - mae: 27402.2656 - val_loss: 30464.8496 - val_mse: 4514961920.0000 - val_mae: 30464.8496\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27474.1895 - mse: 1785097856.0000 - mae: 27474.1875 - val_loss: 30719.3633 - val_mse: 4364668416.0000 - val_mae: 30719.3633\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27501.2383 - mse: 1775811584.0000 - mae: 27501.2383 - val_loss: 30505.6895 - val_mse: 4406341632.0000 - val_mae: 30505.6895\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27442.5605 - mse: 1785658752.0000 - mae: 27442.5605 - val_loss: 30649.1367 - val_mse: 4362435584.0000 - val_mae: 30649.1367\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27461.2246 - mse: 1792290176.0000 - mae: 27461.2246 - val_loss: 30444.9277 - val_mse: 4560733696.0000 - val_mae: 30444.9277\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27555.1309 - mse: 1807431808.0000 - mae: 27555.1309 - val_loss: 30427.2051 - val_mse: 4457667584.0000 - val_mae: 30427.2051\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27477.6953 - mse: 1783762304.0000 - mae: 27477.6953 - val_loss: 30647.1504 - val_mse: 4386734080.0000 - val_mae: 30647.1504\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27455.2637 - mse: 1792736640.0000 - mae: 27455.2637 - val_loss: 30651.3086 - val_mse: 4367849472.0000 - val_mae: 30651.3086\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27487.4512 - mse: 1785364992.0000 - mae: 27487.4512 - val_loss: 30411.7695 - val_mse: 4454171648.0000 - val_mae: 30411.7695\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27394.7344 - mse: 1782275712.0000 - mae: 27394.7344 - val_loss: 30435.0586 - val_mse: 4425059328.0000 - val_mae: 30435.0586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27467.7715 - mse: 1784024448.0000 - mae: 27467.7715 - val_loss: 30390.4785 - val_mse: 4503810048.0000 - val_mae: 30390.4785\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27442.1641 - mse: 1790171392.0000 - mae: 27442.1641 - val_loss: 30400.1348 - val_mse: 4502003712.0000 - val_mae: 30400.1348\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27362.6953 - mse: 1787307264.0000 - mae: 27362.6953 - val_loss: 30663.2734 - val_mse: 4362453504.0000 - val_mae: 30663.2734\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27460.0645 - mse: 1794018560.0000 - mae: 27460.0645 - val_loss: 30451.6270 - val_mse: 4416010752.0000 - val_mae: 30451.6270\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27395.5156 - mse: 1789259392.0000 - mae: 27395.5156 - val_loss: 30367.0664 - val_mse: 4531778048.0000 - val_mae: 30367.0664\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27550.8730 - mse: 1785535744.0000 - mae: 27550.8730 - val_loss: 30369.9902 - val_mse: 4461939712.0000 - val_mae: 30369.9902\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27415.2617 - mse: 1799505920.0000 - mae: 27415.2617 - val_loss: 30470.1699 - val_mse: 4413121024.0000 - val_mae: 30470.1699\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27348.7559 - mse: 1782899072.0000 - mae: 27348.7559 - val_loss: 30532.4043 - val_mse: 4396866048.0000 - val_mae: 30532.4043\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27393.2168 - mse: 1779464576.0000 - mae: 27393.2168 - val_loss: 30624.3398 - val_mse: 4371762688.0000 - val_mae: 30624.3398\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27413.8105 - mse: 1786648448.0000 - mae: 27413.8105 - val_loss: 30392.7559 - val_mse: 4431708672.0000 - val_mae: 30392.7559\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27416.5820 - mse: 1785182464.0000 - mae: 27416.5820 - val_loss: 30362.8242 - val_mse: 4485430784.0000 - val_mae: 30362.8242\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27365.4551 - mse: 1782455808.0000 - mae: 27365.4551 - val_loss: 30584.7070 - val_mse: 4376161280.0000 - val_mae: 30584.7070\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27369.5605 - mse: 1790704896.0000 - mae: 27369.5605 - val_loss: 30410.2617 - val_mse: 4419732992.0000 - val_mae: 30410.2617\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27469.0879 - mse: 1791965184.0000 - mae: 27469.0879 - val_loss: 30428.1641 - val_mse: 4415623168.0000 - val_mae: 30428.1641\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27380.5000 - mse: 1795891584.0000 - mae: 27380.5000 - val_loss: 30361.0957 - val_mse: 4493857792.0000 - val_mae: 30361.0957\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27323.9336 - mse: 1771121664.0000 - mae: 27323.9336 - val_loss: 30374.2246 - val_mse: 4464787968.0000 - val_mae: 30374.2246\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 27334.9766 - mse: 1779078272.0000 - mae: 27334.9766 - val_loss: 30366.3613 - val_mse: 4438929408.0000 - val_mae: 30366.3613\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27350.9375 - mse: 1773723520.0000 - mae: 27350.9375 - val_loss: 30464.5273 - val_mse: 4403423232.0000 - val_mae: 30464.5273\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27339.0723 - mse: 1787915008.0000 - mae: 27339.0723 - val_loss: 30324.5234 - val_mse: 4494008320.0000 - val_mae: 30324.5234\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27289.7070 - mse: 1776386304.0000 - mae: 27289.7070 - val_loss: 30463.2051 - val_mse: 4391121408.0000 - val_mae: 30463.2051\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27439.9824 - mse: 1786056576.0000 - mae: 27439.9824 - val_loss: 30335.9570 - val_mse: 4450501120.0000 - val_mae: 30335.9570\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27286.9746 - mse: 1768876288.0000 - mae: 27286.9746 - val_loss: 30319.2793 - val_mse: 4448931840.0000 - val_mae: 30319.2793\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27207.6543 - mse: 1764226432.0000 - mae: 27207.6543 - val_loss: 31191.9609 - val_mse: 4305228800.0000 - val_mae: 31191.9609\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27411.5312 - mse: 1777550720.0000 - mae: 27411.5312 - val_loss: 30300.2207 - val_mse: 4459056128.0000 - val_mae: 30300.2207\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27318.9023 - mse: 1783553664.0000 - mae: 27318.9023 - val_loss: 30451.4238 - val_mse: 4393543680.0000 - val_mae: 30451.4238\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27400.5859 - mse: 1787869440.0000 - mae: 27400.5859 - val_loss: 30323.8945 - val_mse: 4518964736.0000 - val_mae: 30323.8945\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27379.0430 - mse: 1787029632.0000 - mae: 27379.0430 - val_loss: 30448.2422 - val_mse: 4409098752.0000 - val_mae: 30448.2422\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27350.5156 - mse: 1778261120.0000 - mae: 27350.5156 - val_loss: 30332.4922 - val_mse: 4428888064.0000 - val_mae: 30332.4922\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27348.1523 - mse: 1782563072.0000 - mae: 27348.1523 - val_loss: 30310.4375 - val_mse: 4460346880.0000 - val_mae: 30310.4375\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27330.4609 - mse: 1780434304.0000 - mae: 27330.4609 - val_loss: 30314.1094 - val_mse: 4457282560.0000 - val_mae: 30314.1094\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27285.1523 - mse: 1781643008.0000 - mae: 27285.1523 - val_loss: 30321.5137 - val_mse: 4441634304.0000 - val_mae: 30321.5137\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27308.2266 - mse: 1779780864.0000 - mae: 27308.2266 - val_loss: 30291.5137 - val_mse: 4489383936.0000 - val_mae: 30291.5137\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27237.4727 - mse: 1778285312.0000 - mae: 27237.4727 - val_loss: 30278.4473 - val_mse: 4523837952.0000 - val_mae: 30278.4473\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27244.9316 - mse: 1785669248.0000 - mae: 27244.9316 - val_loss: 30277.7812 - val_mse: 4460104704.0000 - val_mae: 30277.7812\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27293.9062 - mse: 1780918272.0000 - mae: 27293.9062 - val_loss: 30680.2676 - val_mse: 4355596288.0000 - val_mae: 30680.2676\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27297.2324 - mse: 1784293888.0000 - mae: 27297.2324 - val_loss: 30354.5547 - val_mse: 4417347072.0000 - val_mae: 30354.5547\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27267.9336 - mse: 1779244672.0000 - mae: 27267.9336 - val_loss: 30335.3633 - val_mse: 4422212096.0000 - val_mae: 30335.3633\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27322.4082 - mse: 1784943616.0000 - mae: 27322.4082 - val_loss: 30372.5000 - val_mse: 4402989056.0000 - val_mae: 30372.5000\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27282.9668 - mse: 1777120256.0000 - mae: 27282.9668 - val_loss: 30267.5430 - val_mse: 4483366400.0000 - val_mae: 30267.5430\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27276.0664 - mse: 1781511168.0000 - mae: 27276.0664 - val_loss: 30430.3145 - val_mse: 4402205184.0000 - val_mae: 30430.3145\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27292.6328 - mse: 1761143296.0000 - mae: 27292.6328 - val_loss: 30270.9023 - val_mse: 4441624064.0000 - val_mae: 30270.9023\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 27199.0625 - mse: 1765722496.0000 - mae: 27199.0625 - val_loss: 30366.6836 - val_mse: 4410489344.0000 - val_mae: 30366.6836\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27267.5586 - mse: 1781710336.0000 - mae: 27267.5586 - val_loss: 30480.0430 - val_mse: 4377651200.0000 - val_mae: 30480.0430\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27231.1113 - mse: 1761759616.0000 - mae: 27231.1113 - val_loss: 30418.3926 - val_mse: 4383398400.0000 - val_mae: 30418.3926\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27361.0352 - mse: 1804435712.0000 - mae: 27361.0352 - val_loss: 30390.6836 - val_mse: 4410821632.0000 - val_mae: 30390.6836\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27174.3184 - mse: 1773741184.0000 - mae: 27174.3184 - val_loss: 30279.1328 - val_mse: 4489417728.0000 - val_mae: 30279.1328\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27244.3594 - mse: 1784047360.0000 - mae: 27244.3594 - val_loss: 30334.2461 - val_mse: 4424245248.0000 - val_mae: 30334.2461\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27207.4336 - mse: 1772556672.0000 - mae: 27207.4336 - val_loss: 30437.9180 - val_mse: 4388849664.0000 - val_mae: 30437.9180\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27227.2324 - mse: 1775846912.0000 - mae: 27227.2324 - val_loss: 30227.5449 - val_mse: 4463654400.0000 - val_mae: 30227.5449\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27185.5469 - mse: 1769025664.0000 - mae: 27185.5469 - val_loss: 30236.3730 - val_mse: 4553037824.0000 - val_mae: 30236.3730\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27271.8691 - mse: 1778159616.0000 - mae: 27271.8691 - val_loss: 30241.2422 - val_mse: 4438244352.0000 - val_mae: 30241.2422\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27213.3418 - mse: 1761313536.0000 - mae: 27213.3418 - val_loss: 30280.8262 - val_mse: 4429680640.0000 - val_mae: 30280.8262\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27234.4922 - mse: 1767532672.0000 - mae: 27234.4922 - val_loss: 30203.4883 - val_mse: 4493728768.0000 - val_mae: 30203.4883\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27207.8555 - mse: 1767956608.0000 - mae: 27207.8555 - val_loss: 30215.5664 - val_mse: 4527024640.0000 - val_mae: 30215.5664\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27221.7188 - mse: 1768088960.0000 - mae: 27221.7188 - val_loss: 30292.1934 - val_mse: 4409835520.0000 - val_mae: 30292.1934\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27258.6074 - mse: 1777825152.0000 - mae: 27258.6074 - val_loss: 30205.1387 - val_mse: 4489290752.0000 - val_mae: 30205.1387\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27196.8457 - mse: 1774769408.0000 - mae: 27196.8457 - val_loss: 30318.1133 - val_mse: 4410412032.0000 - val_mae: 30318.1133\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27176.1387 - mse: 1773991040.0000 - mae: 27176.1387 - val_loss: 30218.3906 - val_mse: 4486642688.0000 - val_mae: 30218.3906\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27153.7715 - mse: 1765187456.0000 - mae: 27153.7715 - val_loss: 30229.7324 - val_mse: 4525505536.0000 - val_mae: 30229.7324\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27114.5137 - mse: 1754953728.0000 - mae: 27114.5137 - val_loss: 30244.8594 - val_mse: 4431160320.0000 - val_mae: 30244.8594\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27092.0566 - mse: 1760303360.0000 - mae: 27092.0586 - val_loss: 30770.2051 - val_mse: 4340727808.0000 - val_mae: 30770.2051\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27283.5332 - mse: 1776880384.0000 - mae: 27283.5332 - val_loss: 30404.3398 - val_mse: 4383102464.0000 - val_mae: 30404.3398\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27132.2070 - mse: 1763769088.0000 - mae: 27132.2070 - val_loss: 30193.3691 - val_mse: 4459646464.0000 - val_mae: 30193.3691\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27067.3320 - mse: 1755071488.0000 - mae: 27067.3320 - val_loss: 30309.6367 - val_mse: 4589313536.0000 - val_mae: 30309.6367\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27327.1836 - mse: 1776702976.0000 - mae: 27327.1836 - val_loss: 30234.1270 - val_mse: 4521963520.0000 - val_mae: 30234.1270\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27129.5020 - mse: 1770049280.0000 - mae: 27129.5020 - val_loss: 30186.9727 - val_mse: 4472822272.0000 - val_mae: 30186.9727\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27167.8125 - mse: 1772511616.0000 - mae: 27167.8125 - val_loss: 30194.2949 - val_mse: 4536452096.0000 - val_mae: 30194.2949\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27098.0293 - mse: 1760994816.0000 - mae: 27098.0293 - val_loss: 30179.3477 - val_mse: 4512276992.0000 - val_mae: 30179.3477\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27153.8008 - mse: 1756215808.0000 - mae: 27153.8008 - val_loss: 30280.7207 - val_mse: 4415692800.0000 - val_mae: 30280.7207\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27107.4727 - mse: 1770378624.0000 - mae: 27107.4727 - val_loss: 30329.8730 - val_mse: 4402308608.0000 - val_mae: 30329.8730\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27103.1543 - mse: 1769250048.0000 - mae: 27103.1543 - val_loss: 30171.2520 - val_mse: 4482085888.0000 - val_mae: 30171.2520\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27111.7832 - mse: 1772627712.0000 - mae: 27111.7832 - val_loss: 30403.4551 - val_mse: 4364158464.0000 - val_mae: 30403.4551\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27164.4668 - mse: 1772723456.0000 - mae: 27164.4668 - val_loss: 30194.0156 - val_mse: 4545698304.0000 - val_mae: 30194.0156\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 27132.1758 - mse: 1765170688.0000 - mae: 27132.1758 - val_loss: 30243.4883 - val_mse: 4581750272.0000 - val_mae: 30243.4883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x273d66a8ac8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUtnWyC60ls5"
   },
   "source": [
    "Finally, try your model using mean squared logarithmic error. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UjcqV1Zm0ls1"
   },
   "outputs": [],
   "source": [
    "# Answer below:\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_logarithmic_error', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.0470 - mse: 1560106496.0000 - mae: 28053.8848WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0410 - mse: 1791410304.0000 - mae: 27246.4336 - val_loss: 0.0541 - val_mse: 4379306496.0000 - val_mae: 30322.8027\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 1768697856.0000 - mae: 27260.5469 - val_loss: 0.0536 - val_mse: 4335779840.0000 - val_mae: 30562.4023\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 1787996544.0000 - mae: 27397.1465 - val_loss: 0.0537 - val_mse: 4346420736.0000 - val_mae: 30427.0234\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 1792217088.0000 - mae: 27332.8477 - val_loss: 0.0538 - val_mse: 4360392192.0000 - val_mae: 30330.2578\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 1803784832.0000 - mae: 27469.3301 - val_loss: 0.0542 - val_mse: 4393226240.0000 - val_mae: 30159.3613\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 1787516032.0000 - mae: 27220.7637 - val_loss: 0.0535 - val_mse: 4326164992.0000 - val_mae: 30506.1230\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 1799537920.0000 - mae: 27358.8984 - val_loss: 0.0539 - val_mse: 4367666176.0000 - val_mae: 30251.8652\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 1792714112.0000 - mae: 27277.1562 - val_loss: 0.0536 - val_mse: 4331872768.0000 - val_mae: 30411.0117\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 1797540864.0000 - mae: 27394.5781 - val_loss: 0.0532 - val_mse: 4285268224.0000 - val_mae: 30893.5254\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 1816144896.0000 - mae: 27454.5645 - val_loss: 0.0535 - val_mse: 4324995072.0000 - val_mae: 30409.6973\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0399 - mse: 1816610560.0000 - mae: 27452.9883 - val_loss: 0.0535 - val_mse: 4319479808.0000 - val_mae: 30409.7441\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 1783744512.0000 - mae: 27365.9043 - val_loss: 0.0531 - val_mse: 4278756352.0000 - val_mae: 30829.3398\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 1823699840.0000 - mae: 27558.7637 - val_loss: 0.0536 - val_mse: 4324896256.0000 - val_mae: 30318.5840\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 1805524096.0000 - mae: 27365.7012 - val_loss: 0.0532 - val_mse: 4284821248.0000 - val_mae: 30745.7734\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 1816492800.0000 - mae: 27433.4941 - val_loss: 0.0533 - val_mse: 4295700480.0000 - val_mae: 30606.4043\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 1801272320.0000 - mae: 27433.5938 - val_loss: 0.0531 - val_mse: 4248595456.0000 - val_mae: 31352.0312\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 1828147328.0000 - mae: 27645.9785 - val_loss: 0.0533 - val_mse: 4295334912.0000 - val_mae: 30473.8887\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 1798096896.0000 - mae: 27414.5801 - val_loss: 0.0532 - val_mse: 4282436096.0000 - val_mae: 30663.7598\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 1809225216.0000 - mae: 27475.9512 - val_loss: 0.0531 - val_mse: 4274061056.0000 - val_mae: 30700.8809\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 1818412160.0000 - mae: 27498.5547 - val_loss: 0.0531 - val_mse: 4267597568.0000 - val_mae: 30751.4316\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 1810764288.0000 - mae: 27436.5195 - val_loss: 0.0530 - val_mse: 4258842624.0000 - val_mae: 30829.0488\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 1830323456.0000 - mae: 27595.2969 - val_loss: 0.0532 - val_mse: 4276831488.0000 - val_mae: 30567.0801\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 1811121152.0000 - mae: 27356.6719 - val_loss: 0.0531 - val_mse: 4235219968.0000 - val_mae: 31564.3535\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 1824940800.0000 - mae: 27586.1230 - val_loss: 0.0533 - val_mse: 4284438272.0000 - val_mae: 30418.2109\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 1824257664.0000 - mae: 27496.3203 - val_loss: 0.0541 - val_mse: 4338381824.0000 - val_mae: 30113.1973\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 1826237056.0000 - mae: 27510.7129 - val_loss: 0.0536 - val_mse: 4306286592.0000 - val_mae: 30194.7617\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 1803747584.0000 - mae: 27404.2910 - val_loss: 0.0531 - val_mse: 4270455040.0000 - val_mae: 30502.1719\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 1813217536.0000 - mae: 27417.2363 - val_loss: 0.0531 - val_mse: 4268731136.0000 - val_mae: 30496.2441\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 1812061696.0000 - mae: 27520.8184 - val_loss: 0.0530 - val_mse: 4261572096.0000 - val_mae: 30565.2148\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 1818226944.0000 - mae: 27466.7480 - val_loss: 0.0530 - val_mse: 4259418368.0000 - val_mae: 30565.9277\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 1820286080.0000 - mae: 27501.2754 - val_loss: 0.0535 - val_mse: 4292481024.0000 - val_mae: 30191.7480\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 1807218432.0000 - mae: 27387.4980 - val_loss: 0.0527 - val_mse: 4223313408.0000 - val_mae: 31094.9922\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 1841290112.0000 - mae: 27643.0547 - val_loss: 0.0532 - val_mse: 4273125888.0000 - val_mae: 30243.1973\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 1816316416.0000 - mae: 27424.9629 - val_loss: 0.0528 - val_mse: 4238545408.0000 - val_mae: 30669.0234\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 1814413952.0000 - mae: 27441.8574 - val_loss: 0.0526 - val_mse: 4220665088.0000 - val_mae: 30887.5273\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 1820195072.0000 - mae: 27605.4336 - val_loss: 0.0531 - val_mse: 4265137152.0000 - val_mae: 30196.1973\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 1810324992.0000 - mae: 27424.0371 - val_loss: 0.0527 - val_mse: 4232331264.0000 - val_mae: 30524.7891\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 1810521472.0000 - mae: 27370.1582 - val_loss: 0.0526 - val_mse: 4218894592.0000 - val_mae: 30949.8672\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 1815485568.0000 - mae: 27373.5566 - val_loss: 0.0529 - val_mse: 4254524416.0000 - val_mae: 30317.0098\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 1808093056.0000 - mae: 27472.5117 - val_loss: 0.0530 - val_mse: 4257335040.0000 - val_mae: 30259.4727\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 1813564288.0000 - mae: 27369.6074 - val_loss: 0.0529 - val_mse: 4252072960.0000 - val_mae: 30307.2598\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1812174080.0000 - mae: 27360.8496 - val_loss: 0.0530 - val_mse: 4260806912.0000 - val_mae: 30201.5703\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 1806463872.0000 - mae: 27314.5117 - val_loss: 0.0525 - val_mse: 4221740800.0000 - val_mae: 30573.2793\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 1837430400.0000 - mae: 27438.9902 - val_loss: 0.0529 - val_mse: 4249434368.0000 - val_mae: 30199.4883\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 1809481216.0000 - mae: 27411.1445 - val_loss: 0.0525 - val_mse: 4220788736.0000 - val_mae: 30509.3652\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1805855616.0000 - mae: 27372.2363 - val_loss: 0.0525 - val_mse: 4219725056.0000 - val_mae: 30458.7344\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 1809226624.0000 - mae: 27331.8008 - val_loss: 0.0524 - val_mse: 4213997824.0000 - val_mae: 30556.8418\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 1800394496.0000 - mae: 27363.6699 - val_loss: 0.0525 - val_mse: 4227531776.0000 - val_mae: 30484.0352\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1818307584.0000 - mae: 27380.2070 - val_loss: 0.0529 - val_mse: 4253954304.0000 - val_mae: 30108.0566\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1793202944.0000 - mae: 27233.5938 - val_loss: 0.0523 - val_mse: 4191085312.0000 - val_mae: 31069.6465\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 1825145600.0000 - mae: 27400.8828 - val_loss: 0.0523 - val_mse: 4191876352.0000 - val_mae: 31094.1484\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1825191424.0000 - mae: 27474.9160 - val_loss: 0.0526 - val_mse: 4234676992.0000 - val_mae: 30287.4043\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1794419712.0000 - mae: 27284.5723 - val_loss: 0.0522 - val_mse: 4200988672.0000 - val_mae: 30660.3809\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1795431168.0000 - mae: 27281.6895 - val_loss: 0.0522 - val_mse: 4196975104.0000 - val_mae: 30709.9512\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1822533376.0000 - mae: 27474.0176 - val_loss: 0.0525 - val_mse: 4223878656.0000 - val_mae: 30216.5391\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 1804146944.0000 - mae: 27320.3574 - val_loss: 0.0531 - val_mse: 4263169280.0000 - val_mae: 29940.4609\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1790908288.0000 - mae: 27241.4766 - val_loss: 0.0527 - val_mse: 4240657152.0000 - val_mae: 30149.8398\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1762660736.0000 - mae: 27012.0293 - val_loss: 0.0522 - val_mse: 4188106496.0000 - val_mae: 31089.6445\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 1811014912.0000 - mae: 27304.1230 - val_loss: 0.0523 - val_mse: 4208275456.0000 - val_mae: 30459.6465\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 1805587200.0000 - mae: 27329.0879 - val_loss: 0.0527 - val_mse: 4241209856.0000 - val_mae: 30046.7852\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 1792825984.0000 - mae: 27217.5684 - val_loss: 0.0522 - val_mse: 4202538752.0000 - val_mae: 30614.0898\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 1802938496.0000 - mae: 27286.3633 - val_loss: 0.0525 - val_mse: 4228388352.0000 - val_mae: 30195.9961\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 1804170112.0000 - mae: 27231.3242 - val_loss: 0.0523 - val_mse: 4213661440.0000 - val_mae: 30347.6035\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 1799306112.0000 - mae: 27236.1250 - val_loss: 0.0523 - val_mse: 4220038144.0000 - val_mae: 30248.5625\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 1807814272.0000 - mae: 27265.4180 - val_loss: 0.0523 - val_mse: 4217913088.0000 - val_mae: 30199.8398\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 1800059264.0000 - mae: 27307.6855 - val_loss: 0.0522 - val_mse: 4209102592.0000 - val_mae: 30358.8398\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 1785776000.0000 - mae: 27230.4980 - val_loss: 0.0525 - val_mse: 4239711488.0000 - val_mae: 30070.8887\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 1790335872.0000 - mae: 27206.6797 - val_loss: 0.0530 - val_mse: 4269908480.0000 - val_mae: 29842.7852\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 1794543872.0000 - mae: 27159.9492 - val_loss: 0.0528 - val_mse: 4264699136.0000 - val_mae: 29926.3691\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 1783290752.0000 - mae: 27205.1016 - val_loss: 0.0533 - val_mse: 4287925248.0000 - val_mae: 29724.9277\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 1777844480.0000 - mae: 27010.0293 - val_loss: 0.0523 - val_mse: 4226170624.0000 - val_mae: 30300.9590\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 1792765312.0000 - mae: 27215.2441 - val_loss: 0.0526 - val_mse: 4245310976.0000 - val_mae: 29954.8535\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 1793135616.0000 - mae: 27196.5117 - val_loss: 0.0524 - val_mse: 4234019840.0000 - val_mae: 30098.4180\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1781262208.0000 - mae: 27143.1465 - val_loss: 0.0521 - val_mse: 4208840192.0000 - val_mae: 30348.6777\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1783158016.0000 - mae: 27128.5742 - val_loss: 0.0522 - val_mse: 4226108672.0000 - val_mae: 30245.0840\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1782042752.0000 - mae: 27104.7305 - val_loss: 0.0520 - val_mse: 4192263168.0000 - val_mae: 30744.1504\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 1795640832.0000 - mae: 27288.2188 - val_loss: 0.0521 - val_mse: 4215792128.0000 - val_mae: 30378.1914\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1794505984.0000 - mae: 27149.1621 - val_loss: 0.0522 - val_mse: 4225717248.0000 - val_mae: 30280.5137\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1788153984.0000 - mae: 27174.9648 - val_loss: 0.0524 - val_mse: 4241987840.0000 - val_mae: 30003.4414\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 1765706368.0000 - mae: 27012.8809 - val_loss: 0.0520 - val_mse: 4184070912.0000 - val_mae: 31182.9316\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1807725312.0000 - mae: 27258.8613 - val_loss: 0.0525 - val_mse: 4250977024.0000 - val_mae: 29926.3887\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 1781039232.0000 - mae: 27106.9688 - val_loss: 0.0521 - val_mse: 4220797184.0000 - val_mae: 30330.9707\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 1778937856.0000 - mae: 27063.5430 - val_loss: 0.0521 - val_mse: 4223675904.0000 - val_mae: 30225.1484\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1781392256.0000 - mae: 27076.2715 - val_loss: 0.0520 - val_mse: 4216592640.0000 - val_mae: 30289.2676\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1787689344.0000 - mae: 27236.0664 - val_loss: 0.0527 - val_mse: 4271717632.0000 - val_mae: 29766.6191\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 1765422080.0000 - mae: 26981.8945 - val_loss: 0.0522 - val_mse: 4236520192.0000 - val_mae: 30055.7676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 1755321600.0000 - mae: 26901.8770 - val_loss: 0.0519 - val_mse: 4198160640.0000 - val_mae: 30745.9473\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 1783572224.0000 - mae: 27064.1094 - val_loss: 0.0519 - val_mse: 4204001280.0000 - val_mae: 30518.3672\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 1780754048.0000 - mae: 27134.3047 - val_loss: 0.0525 - val_mse: 4261132544.0000 - val_mae: 29785.1914\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 1768907520.0000 - mae: 27078.6523 - val_loss: 0.0520 - val_mse: 4221358336.0000 - val_mae: 30192.6934\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 1784383360.0000 - mae: 27131.3711 - val_loss: 0.0533 - val_mse: 4318359552.0000 - val_mae: 29527.3398\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1765816960.0000 - mae: 26978.5449 - val_loss: 0.0519 - val_mse: 4211503360.0000 - val_mae: 30707.9590\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 1779354240.0000 - mae: 27098.1641 - val_loss: 0.0519 - val_mse: 4217524992.0000 - val_mae: 30217.0273\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 1770555520.0000 - mae: 27011.0977 - val_loss: 0.0519 - val_mse: 4216930048.0000 - val_mae: 30360.6055\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 1795993472.0000 - mae: 27139.3438 - val_loss: 0.0521 - val_mse: 4235319040.0000 - val_mae: 30033.1367\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 1766936832.0000 - mae: 26857.4473 - val_loss: 0.0519 - val_mse: 4215226624.0000 - val_mae: 30385.1875\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 1780165376.0000 - mae: 27031.8164 - val_loss: 0.0519 - val_mse: 4226619648.0000 - val_mae: 30219.0840\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 1776689152.0000 - mae: 26999.4805 - val_loss: 0.0518 - val_mse: 4211120384.0000 - val_mae: 30463.5508\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 1772915200.0000 - mae: 27028.0859 - val_loss: 0.0520 - val_mse: 4235178496.0000 - val_mae: 30189.2109\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 1766730112.0000 - mae: 26900.6172 - val_loss: 0.0519 - val_mse: 4229100800.0000 - val_mae: 30152.8750\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 1778420864.0000 - mae: 26934.4863 - val_loss: 0.0519 - val_mse: 4229236992.0000 - val_mae: 30123.5566\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 1770755456.0000 - mae: 27009.5430 - val_loss: 0.0524 - val_mse: 4267667456.0000 - val_mae: 29772.1309\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 1770668288.0000 - mae: 26884.8105 - val_loss: 0.0519 - val_mse: 4234320640.0000 - val_mae: 30176.1855\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 1785211520.0000 - mae: 27079.5586 - val_loss: 0.0527 - val_mse: 4287491328.0000 - val_mae: 29545.2461\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 1757488896.0000 - mae: 26893.5938 - val_loss: 0.0520 - val_mse: 4236486400.0000 - val_mae: 30014.1797\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 1771789696.0000 - mae: 26907.6367 - val_loss: 0.0524 - val_mse: 4278434816.0000 - val_mae: 29688.9492\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 1758561152.0000 - mae: 26858.7559 - val_loss: 0.0517 - val_mse: 4215797760.0000 - val_mae: 30331.5996\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 1781944448.0000 - mae: 26987.2324 - val_loss: 0.0519 - val_mse: 4235432704.0000 - val_mae: 30108.1094\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1762264576.0000 - mae: 26855.3164 - val_loss: 0.0517 - val_mse: 4208367360.0000 - val_mae: 30549.0352\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 1782885504.0000 - mae: 26964.7246 - val_loss: 0.0526 - val_mse: 4294483968.0000 - val_mae: 29508.9492\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 1766611840.0000 - mae: 26805.0566 - val_loss: 0.0519 - val_mse: 4235457280.0000 - val_mae: 30047.2871\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1756171264.0000 - mae: 26823.6699 - val_loss: 0.0518 - val_mse: 4229815296.0000 - val_mae: 30182.9336\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1761085952.0000 - mae: 26815.9004 - val_loss: 0.0519 - val_mse: 4239703040.0000 - val_mae: 30021.0215\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1749882496.0000 - mae: 26817.3652 - val_loss: 0.0518 - val_mse: 4214045184.0000 - val_mae: 30635.7266\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1779374336.0000 - mae: 26943.1973 - val_loss: 0.0528 - val_mse: 4310431744.0000 - val_mae: 29423.5762\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 1761425280.0000 - mae: 26799.1895 - val_loss: 0.0523 - val_mse: 4281614592.0000 - val_mae: 29644.6523\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1750392448.0000 - mae: 26855.8164 - val_loss: 0.0526 - val_mse: 4302582272.0000 - val_mae: 29467.2344\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1752425088.0000 - mae: 26807.0898 - val_loss: 0.0520 - val_mse: 4256530688.0000 - val_mae: 29924.5801\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 1763059456.0000 - mae: 26791.3730 - val_loss: 0.0520 - val_mse: 4255578112.0000 - val_mae: 29951.3457\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 1762866688.0000 - mae: 26810.1855 - val_loss: 0.0519 - val_mse: 4249655808.0000 - val_mae: 30102.8535\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1752918272.0000 - mae: 26815.6016 - val_loss: 0.0520 - val_mse: 4260845312.0000 - val_mae: 29983.8652\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 1761262976.0000 - mae: 26846.1621 - val_loss: 0.0519 - val_mse: 4251855872.0000 - val_mae: 30075.4102\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1739172096.0000 - mae: 26735.6602 - val_loss: 0.0518 - val_mse: 4230214656.0000 - val_mae: 30701.4453\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1767541888.0000 - mae: 26916.4590 - val_loss: 0.0521 - val_mse: 4277975296.0000 - val_mae: 29845.2656\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1764251776.0000 - mae: 26832.5254 - val_loss: 0.0526 - val_mse: 4313182720.0000 - val_mae: 29469.2070\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1754706304.0000 - mae: 26678.5312 - val_loss: 0.0523 - val_mse: 4301034496.0000 - val_mae: 29671.0234\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1739483776.0000 - mae: 26697.4688 - val_loss: 0.0518 - val_mse: 4223449344.0000 - val_mae: 30685.5078\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1762324992.0000 - mae: 26898.1230 - val_loss: 0.0521 - val_mse: 4276084224.0000 - val_mae: 29736.3672\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1763044864.0000 - mae: 26795.3789 - val_loss: 0.0524 - val_mse: 4300505600.0000 - val_mae: 29489.5684\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1733247232.0000 - mae: 26583.4141 - val_loss: 0.0518 - val_mse: 4245755136.0000 - val_mae: 30196.9043\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1749572736.0000 - mae: 26780.1719 - val_loss: 0.0517 - val_mse: 4239684608.0000 - val_mae: 30216.7539\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1764921472.0000 - mae: 26868.9531 - val_loss: 0.0523 - val_mse: 4296901120.0000 - val_mae: 29606.0098\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1749825536.0000 - mae: 26671.7070 - val_loss: 0.0518 - val_mse: 4249897728.0000 - val_mae: 30046.5000\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1753156352.0000 - mae: 26716.6406 - val_loss: 0.0522 - val_mse: 4290007552.0000 - val_mae: 29608.7559\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1737783680.0000 - mae: 26644.1602 - val_loss: 0.0518 - val_mse: 4255755520.0000 - val_mae: 30161.4961\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1764237952.0000 - mae: 26906.2168 - val_loss: 0.0524 - val_mse: 4313433088.0000 - val_mae: 29487.2070\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 1737369984.0000 - mae: 26593.6562 - val_loss: 0.0521 - val_mse: 4283115264.0000 - val_mae: 29711.9707\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1748625280.0000 - mae: 26616.5273 - val_loss: 0.0520 - val_mse: 4274894336.0000 - val_mae: 29772.1250\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1748730368.0000 - mae: 26663.8672 - val_loss: 0.0522 - val_mse: 4293101056.0000 - val_mae: 29580.1191\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1741436032.0000 - mae: 26716.1250 - val_loss: 0.0521 - val_mse: 4290348288.0000 - val_mae: 29638.6582\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1738302464.0000 - mae: 26624.0078 - val_loss: 0.0518 - val_mse: 4258230528.0000 - val_mae: 29935.7949\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1733965824.0000 - mae: 26686.9141 - val_loss: 0.0519 - val_mse: 4266830080.0000 - val_mae: 30245.8398\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1744407936.0000 - mae: 26708.1230 - val_loss: 0.0518 - val_mse: 4256872960.0000 - val_mae: 30238.1855\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1750669824.0000 - mae: 26607.2539 - val_loss: 0.0517 - val_mse: 4254245888.0000 - val_mae: 30185.3672\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1767233152.0000 - mae: 26762.9980 - val_loss: 0.0518 - val_mse: 4263215616.0000 - val_mae: 29900.1895\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1723374848.0000 - mae: 26578.0625 - val_loss: 0.0517 - val_mse: 4224127744.0000 - val_mae: 30572.0215\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1766631680.0000 - mae: 26832.9746 - val_loss: 0.0517 - val_mse: 4249573632.0000 - val_mae: 30054.4043\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1739677184.0000 - mae: 26583.9688 - val_loss: 0.0516 - val_mse: 4231620864.0000 - val_mae: 30377.9824\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1743058944.0000 - mae: 26710.6484 - val_loss: 0.0522 - val_mse: 4299738112.0000 - val_mae: 29459.1309\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1738162816.0000 - mae: 26653.2500 - val_loss: 0.0528 - val_mse: 4349527552.0000 - val_mae: 29199.7715\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1705852288.0000 - mae: 26381.8262 - val_loss: 0.0517 - val_mse: 4223888640.0000 - val_mae: 30743.8633\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 1760450176.0000 - mae: 26892.2578 - val_loss: 0.0524 - val_mse: 4316201472.0000 - val_mae: 29342.4199\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1735631744.0000 - mae: 26611.3184 - val_loss: 0.0521 - val_mse: 4296632832.0000 - val_mae: 29482.2734\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 1722542720.0000 - mae: 26480.6895 - val_loss: 0.0516 - val_mse: 4227011840.0000 - val_mae: 30438.3105\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1750583296.0000 - mae: 26818.3730 - val_loss: 0.0528 - val_mse: 4350318080.0000 - val_mae: 29176.7852\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1732079232.0000 - mae: 26531.3242 - val_loss: 0.0517 - val_mse: 4263947008.0000 - val_mae: 29816.3555\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 1741395456.0000 - mae: 26546.6562 - val_loss: 0.0517 - val_mse: 4255034624.0000 - val_mae: 29848.8359\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 1743008128.0000 - mae: 26577.2461 - val_loss: 0.0517 - val_mse: 4260475136.0000 - val_mae: 29814.6602\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1747325056.0000 - mae: 26712.9492 - val_loss: 0.0519 - val_mse: 4279700224.0000 - val_mae: 29619.5430\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 1745498112.0000 - mae: 26605.9922 - val_loss: 0.0520 - val_mse: 4291364864.0000 - val_mae: 29455.8828\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 1739903232.0000 - mae: 26510.5918 - val_loss: 0.0525 - val_mse: 4333521408.0000 - val_mae: 29211.7871\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 1742206592.0000 - mae: 26648.5625 - val_loss: 0.0523 - val_mse: 4317333504.0000 - val_mae: 29294.2578\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 1747209472.0000 - mae: 26632.1426 - val_loss: 0.0516 - val_mse: 4249075456.0000 - val_mae: 29901.4609\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 1731501056.0000 - mae: 26597.9492 - val_loss: 0.0519 - val_mse: 4285115648.0000 - val_mae: 29465.3125\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 1729834368.0000 - mae: 26442.2383 - val_loss: 0.0517 - val_mse: 4271094272.0000 - val_mae: 29894.6699\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 1744665600.0000 - mae: 26655.8750 - val_loss: 0.0527 - val_mse: 4354066944.0000 - val_mae: 29136.4590\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 1736698368.0000 - mae: 26501.1113 - val_loss: 0.0518 - val_mse: 4276228864.0000 - val_mae: 29659.8262\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 1726974848.0000 - mae: 26441.4062 - val_loss: 0.0516 - val_mse: 4246735872.0000 - val_mae: 29978.9316\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 1735678592.0000 - mae: 26493.9648 - val_loss: 0.0516 - val_mse: 4260983808.0000 - val_mae: 29922.9473\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 1750019712.0000 - mae: 26645.2539 - val_loss: 0.0523 - val_mse: 4320478208.0000 - val_mae: 29172.1348\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 1728031232.0000 - mae: 26419.5273 - val_loss: 0.0519 - val_mse: 4294444288.0000 - val_mae: 29407.4277\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 1732076032.0000 - mae: 26464.6797 - val_loss: 0.0518 - val_mse: 4285231360.0000 - val_mae: 29479.3340\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 1701939072.0000 - mae: 26309.1094 - val_loss: 0.0517 - val_mse: 4245410816.0000 - val_mae: 30481.9434\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 1745354112.0000 - mae: 26553.9141 - val_loss: 0.0516 - val_mse: 4244323840.0000 - val_mae: 30215.3027\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 1744981504.0000 - mae: 26560.1055 - val_loss: 0.0519 - val_mse: 4292624640.0000 - val_mae: 29468.9863\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 1726842624.0000 - mae: 26459.2871 - val_loss: 0.0518 - val_mse: 4281220608.0000 - val_mae: 29494.1699\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 1730391296.0000 - mae: 26426.6426 - val_loss: 0.0516 - val_mse: 4255905792.0000 - val_mae: 30059.4961\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 1721489664.0000 - mae: 26478.0234 - val_loss: 0.0517 - val_mse: 4272168448.0000 - val_mae: 29694.4062\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 1730469632.0000 - mae: 26441.7949 - val_loss: 0.0523 - val_mse: 4334856192.0000 - val_mae: 29152.9766\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 1740013312.0000 - mae: 26382.1758 - val_loss: 0.0516 - val_mse: 4261428480.0000 - val_mae: 29744.9512\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 1725550208.0000 - mae: 26499.3691 - val_loss: 0.0515 - val_mse: 4246911488.0000 - val_mae: 29965.9844\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 1726550144.0000 - mae: 26375.7441 - val_loss: 0.0514 - val_mse: 4230391552.0000 - val_mae: 30095.7656\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 1735568256.0000 - mae: 26488.7129 - val_loss: 0.0516 - val_mse: 4269002496.0000 - val_mae: 29559.7871\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 1721504768.0000 - mae: 26460.0508 - val_loss: 0.0515 - val_mse: 4254935040.0000 - val_mae: 29964.3359\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 1732029312.0000 - mae: 26492.4297 - val_loss: 0.0516 - val_mse: 4255860736.0000 - val_mae: 30049.6504\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 1729676928.0000 - mae: 26487.0059 - val_loss: 0.0516 - val_mse: 4272474368.0000 - val_mae: 29612.7461\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 1721247360.0000 - mae: 26441.5254 - val_loss: 0.0518 - val_mse: 4291840768.0000 - val_mae: 29385.4863\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 1728356992.0000 - mae: 26509.7012 - val_loss: 0.0521 - val_mse: 4325557760.0000 - val_mae: 29200.6406\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1715637248.0000 - mae: 26257.2402 - val_loss: 0.0516 - val_mse: 4250365184.0000 - val_mae: 30162.7949\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1722823296.0000 - mae: 26407.5059 - val_loss: 0.0515 - val_mse: 4257316608.0000 - val_mae: 29950.1992\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1718190976.0000 - mae: 26376.5195 - val_loss: 0.0516 - val_mse: 4269025792.0000 - val_mae: 29782.1602\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1724366336.0000 - mae: 26446.6484 - val_loss: 0.0518 - val_mse: 4289719552.0000 - val_mae: 29302.1543\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1716630528.0000 - mae: 26359.6855 - val_loss: 0.0520 - val_mse: 4310515712.0000 - val_mae: 29200.2344\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 1702948096.0000 - mae: 26203.7402 - val_loss: 0.0515 - val_mse: 4250231296.0000 - val_mae: 30048.7852\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1710816896.0000 - mae: 26449.7441 - val_loss: 0.0517 - val_mse: 4285897472.0000 - val_mae: 29440.7422\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1721638528.0000 - mae: 26421.2656 - val_loss: 0.0519 - val_mse: 4309736960.0000 - val_mae: 29286.4453\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1707863424.0000 - mae: 26230.6738 - val_loss: 0.0515 - val_mse: 4247019008.0000 - val_mae: 30066.7266\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 1720623488.0000 - mae: 26401.2695 - val_loss: 0.0516 - val_mse: 4273864192.0000 - val_mae: 29529.6914\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 1712024832.0000 - mae: 26328.4395 - val_loss: 0.0516 - val_mse: 4280274688.0000 - val_mae: 29553.5840\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 1702523392.0000 - mae: 26302.0918 - val_loss: 0.0516 - val_mse: 4243306752.0000 - val_mae: 30322.1973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x273d7d215c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 77 Lecture 2 Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
