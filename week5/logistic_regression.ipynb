{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be playing around a little bit more with the *Super Smash Bros. Melee* dataset.  Last time, I promise.  The dataset has been altered to have a larger sample size.  This data generation was intentionally done to lean into logistic regression.\n",
    "\n",
    "We want to predict the outcome variable `won`; this column takes the values `1` or `0`.  A `1` indicates that the player in the row won the set; a `0` indicates that the player lost.\n",
    "\n",
    "Review questions:\n",
    "* What are the two major classes of machine learning problems? What type is this one?\n",
    "* The correct answer to the first question has two major subclasses of machine learning problems, what are they?  Which of the two groups would you put our SSBM task into?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/AdamSpannbauer/twitch_chat/master/data/slippi_data/generated_ssbm.csv\"\n",
    "ssbm = pd.read_csv(data_url).drop(columns=[\"index\"])\n",
    "ssbm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we've already done our EDA and want to get straight into modeling.  How might we start down this road?\n",
    "\n",
    "A good place to start could be to split up our data into it's `X` and `y` components and then doing a train test split.\n",
    "\n",
    "* Our target variable is `won` so we'll call it `y`\n",
    "* The rest of the features (except for the `gamerTag`) we'll call `X`\n",
    "* Use the seed 1969 for the random_state in the train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we only want to move forward with the 2 best predictors of our output variable `won`.  How might we do that?\n",
    "\n",
    "We could use `SelectKBest` from `sklearn.feature_selection`.  We want to use the `f_classif` method to run ANOVAs.  We do this because our features are continuous and our target is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing columns since we're going to overwrite\n",
    "# X with a numpy array (which will delete its column names)\n",
    "cols = X_train.columns\n",
    "\n",
    "# Perform ANOVAs for each of our features and outcome\n",
    "selector = SelectKBest(f_classif, k=2)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# We don't have to transform this back into a dataframe\n",
    "# this is just being done for better display\n",
    "selected_cols = cols[selector.get_support()]\n",
    "X_train = pd.DataFrame(X_train, columns=selected_cols, index=y_train.index)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our remaining 2 features with our target variable.  How do we want to do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe boxplots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe a scatterplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a `LogisticRegression` model and score it on our train and test data.\n",
    "\n",
    "But first! Let's look at what logistic regression is doing.  If we were to just use one of our columns to predict who won, we might look at a scatter plot of that column with the target variable.\n",
    "\n",
    "In doing so, we see a pattern.  In general, the higher the `numKillingPunishes`, the more likely a player is to win.  But how could we draw a line to predict the probability of someone winning based on this info?\n",
    "\n",
    "The trick is that the line doesn't have to be straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\"numKillingPunishes\", \"won\", data=ssbm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll talk about the below code in a couple cells, for now, just now we're using a logisitic regression model to draw some lines on the scatter plot from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to see here.. scroll down to the plot\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train[[\"numKillingPunishes\"]], y_train)\n",
    "\n",
    "pred_df = model.predict_proba(X_train[[\"numKillingPunishes\"]])\n",
    "pred_df = pd.DataFrame(pred_df, columns=[\"prob_lose\", \"prob_win\"])\n",
    "pred_df[\"numKillingPunishes\"] = X_train[\"numKillingPunishes\"].reset_index(drop=True)\n",
    "pred_df = pred_df.sort_values(\"numKillingPunishes\")\n",
    "\n",
    "sns.scatterplot(\"numKillingPunishes\", \"won\", data=ssbm, label=\"Actual\")\n",
    "plt.plot(pred_df[\"numKillingPunishes\"], pred_df[\"prob_win\"], c=\"orange\", label=\"Fit\")\n",
    "plt.axvline(11.42896875, c=\"red\", ls=\"--\", alpha=0.5, label=\"Decision\\nBoundary\")\n",
    "plt.axhline(0.5, c=\"black\", alpha=0.1, label=\"50%\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to predict with more than just one variable! What does that look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(ssbm, \"numKillingPunishes\", \"openingsPerKill\", \"won\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll talk about the below code in a couple cells, for now, just now we're using a logisitic regression model to draw some lines on the scatter plot from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to see here.. scroll down to the plot\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_df = model.predict_proba(X_train)\n",
    "pred_df = pd.DataFrame(pred_df[:, 1], columns=[\"prob_win\"])\n",
    "pred_df[\"numKillingPunishes\"] = X_train[\"numKillingPunishes\"].reset_index(drop=True)\n",
    "pred_df[\"openingsPerKill\"] = X_train[\"openingsPerKill\"].reset_index(drop=True)\n",
    "pred_df[\"won\"] = y_train.reset_index(drop=True)\n",
    "pred_df = pd.melt(\n",
    "    pred_df, id_vars=[\"numKillingPunishes\", \"openingsPerKill\"], var_name=\"won\"\n",
    ")\n",
    "pred_df.loc[pred_df[\"won\"] == \"prob_win\", \"won\"] = \"Fit\"\n",
    "pred_df.loc[pred_df[\"won\"] == \"won\", \"won\"] = \"Actual\"\n",
    "\n",
    "px.scatter_3d(pred_df, \"numKillingPunishes\", \"openingsPerKill\", \"value\", color=\"won\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now to talk about actually fitting the model.\n",
    "\n",
    "* Define a `LogisticRegression` model and `fit` it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ____\n",
    "model.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `score` the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `score` the model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some predictions, and see how our model is making mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = ____\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the confusion matrix to a dataframe\n",
    "* Use `['actual_0', 'actual_1']` for the `index`\n",
    "* Use `['predicted_0', 'predicted_1']` for the `columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize our mistakes we might put our data back into a dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_df = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "diagnostic_df['won'] = y_test.values\n",
    "diagnostic_df['won_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a column indicating `True` or `False` when we made an error in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_df['error'] = ____\n",
    "diagnostic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use `seaborn` like before, but this time let's somehow display whether each observation was an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to be more formal about seeing the decision boundary we could plot using `plot_decision_regions` from `mlextend`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This wants an array that's not the float type\n",
    "labels = y_test.values.astype(int)\n",
    "\n",
    "plot_decision_regions(X_test, labels, clf=model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is actually happening when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_1 = model.coef_[0, 0]\n",
    "coef_2 = model.coef_[0, 1]\n",
    "intercept = model.intercept_[0]\n",
    "\n",
    "print(\n",
    "    f\"log(odds) = {intercept:.2f} + {coef_1:.2f}*numKillingPunishes + {coef_2:.2f}*openingsPerKill\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above shows how we can write the formula that our logistic regression model learned from our data.\n",
    "\n",
    "But we need to get some intuition of what the `log(odds)` means.  Let's see how we could make a prediction 'by hand' with a single observation.\n",
    "\n",
    "First we'll subset out a single observation, we'll call it `obs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = ssbm.loc[[0], ['numKillingPunishes', 'openingsPerKill']]\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fill out the right hand side of the equation and do the math to calculate the value of this `log(odds)` thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = ____\n",
    "X2 = ____\n",
    "\n",
    "log_odds = intercept + coef_1 * X1 + coef_2 * X2\n",
    "# Some manipulation to get to just a number from log_odds (which is a pandas.Series)\n",
    "log_odds = log_odds.values[0]\n",
    "log_odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like it sounds, log(odds) is the log of the odds.  So, to go from log(odds) to odds we need to do $e^{log(odds)}$.  This is because, raising $e$ to x is the inverse of taking the log of x (like how multiplying by x is the inverse of dividing by x).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = np.exp(log_odds)\n",
    "odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the odds as 0.0269.  This number doesn't mean much to me; I'd much prefer probability instead of odds. If you're familiar with odds then you might be comfortable with this number.\n",
    "\n",
    "If we did want to convert to probability we can do the following: $\\frac{odds}{1 + odds}$.  For example, saying \"5 to 1 odds\" ($\\frac{5}{1}$) is the same as saying a probability of $\\frac{5}{6}$ or $0.833$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = odds / (1 + odds)\n",
    "\n",
    "# Formula can be re-written to match the slides\n",
    "# prob = 1 / (1 + np.exp(-log_odds))\n",
    "\n",
    "print(f\"Probability of losing: {1 - prob:.4f}\")\n",
    "print(f\"Probability of winning: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results show that our observation only as a 2.6% chance of winning.  If we wanted to compare this result to what our model would predict, we could use its `predict_proba` method.  This method outputs a probability for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our coefficients and some math, we were able to mimic our `sklearn` model.  But what do these coefficients actually mean?\n",
    "\n",
    "The coefficient for `numKillingPunishes` is 0.7239 which is interpreted as the expected change in log odds for a one-unit increase in `numKillingPunishes`.  For example, if we went from 5 `numKillingPunishes` to 6 `numKillingPunishes` we would see our log odds increase by 0.7239 (aka our coefficient).  This still isn't the most interpretable thing.\n",
    "\n",
    "We can use the coefficient to calculate the *odds ratio* and this will lead us to a little more interpretable result.  To go from our coefficient to this odds ratio we will raise $e$ to it just like we did before.  We can then compare this ratio to 1 to see how it affects our odds of winning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(coef_1) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output of 2.062 is then compared to the value 1 to see how we expect our odds to change for one unit increase in `numKillingPunishes`.  That is, 2.062 - 1 = 1.062.  This means we expect to see a 102% increase in the odds of winning for every unit increase in `numKillingPunishes`.\n",
    "\n",
    "Let's also interpret the coefficient for `openingsPerKill`, which was -1.31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(coef_2) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we expect to see a 73% decrease in the odds of winning for every unit increase of `openingsPerKill`.  That is, if we went from 5 `openingsPerKill` to 6 `openingsPerKill` we would decrease our odds of winning by 73%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
